<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Hatak::Techlog]]></title>
  <link href="http://blog.hatak.net/atom.xml" rel="self"/>
  <link href="http://blog.hatak.net/"/>
  <updated>2014-02-15T08:13:00+09:00</updated>
  <id>http://blog.hatak.net/</id>
  <author>
    <name><![CDATA[Hisashi HATAKEYAMA]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[0歳児との生活]]></title>
    <link href="http://blog.hatak.net/2012/12/17/17651"/>
    <updated>2012-12-17T00:00:00+09:00</updated>
    <id>http://blog.hatak.net/2012/12/17/0%e6%ad%b3%e5%85%90%e3%81%a8%e3%81%ae%e7%94%9f%e6%b4%bb</id>
    <content type="html"><![CDATA[<p>この記事は <a href="http://atnd.org/events/34177">子育てエンジニア advent calendar 2012</a> への参加エントリー（16日目）です。</p>

<p>選挙速報を見ながら書いていたのですが、ぎりぎりになったところで子供に泣かれてあやしていたら日付を超えてしまいましたすみません。。。 様々な政策が再び大きく変わりそうですが、子育て支援をはじめとして親としては気になる内容も多いので見守りつつ書いています。</p>

<!--more-->

<p>今年の1月に子供が産まれました。</p>

<p><img src="https://dl.dropboxusercontent.com/u/14531906/hatak.github.io/2012/12/helloworld-225x300.jpg" alt="Hello World" width="225" height="300" class="alignnone size-medium wp-image-17649" /></p>

<h2 id="toc_332">変わったこと</h2>

<p>生活は大きく変わりました。</p>

<p>例えばおでかけの時。妻と2人で散歩してるときはあまり気にせず公園の中も自由に歩けていましたが、ベビーカーを使っていると特定のスロープを通るルートしか選べなかったり。出かける先も授乳室やおむつ替えスペースがありそうなところであったり、食事をするのも子供連れでも利用できるレストランを探したり。帰ってくるのも遅くなりすぎない時間に戻れるようなスケジュール（しかも、30分程度はバッファを見た上で）をなんとなく考えるようになりました。</p>

<p>そういう意味では、視点も大きく変わったのかなと思います。</p>

<p>買い物も大きく変わった一つかと思います。</p>

<p>妊娠中、重い買い物をしなくても良いようにと個人宅配に加入したのですが、これはとても良い選択でした。休みの日に家族 3 人で買い物にでかけるのは良いのですが、子供をだっこして重い買い物袋をいくつも持ってくるのは大変です。もちろん、平日に妻が子供と2人で毎日買い物に行くことはもっと大変です。 そこで、お米やたまご、常備菜などの重かったり運びにくい食材は宅配にお願いして、必要なものを都度、私が帰りがけに買って帰るなどの運用になりました。宅配の商品は店頭より高かったり、半月ほど前には注文を提出する必要があったりすることもありますが、持ち帰る手間や届く品物の質を考えれば良いかなと考えるようになりました。</p>

<p>また、生活雑貨ではネット通販に大変お世話になっています。中でも一番お世話になっているのは Amazon です。取扱品が多くて探しやすく、店頭価格と比べても変わりない（場合によっては店頭より安いこともある）ので、おむつなどかさばる商品はとても便利です。</p>

<p>ちなみに、最近は &#8220;Amazon ファミリー&#8221; というパパ・ママ向けのサービスをしています。初回登録時のクーポンや Amazon プライム無料お試しなど、特典が魅力的なのでおすすめです。</p>

<p>あとは、周りのお父さんが口を揃えていうことですが、本当に時間がないです。覚悟していた以上でした。 起きているときは一緒に遊んだり見守ったりしますし、寝てるときも突然夜泣きしたり寝ぼけて起き上がったりします。そもそもすんなり寝付いてくれません。寝不足にもなりますし、イライラしてしまうこともあります。 この問題については、未だに試行錯誤の毎日です。どうやって時間を作り、効率良く自分の時間を使い、満足するか。子供と一緒に成長していくしかないのかなと思ったりしています。</p>

<h2 id="toc_333">感じたこと</h2>

<p>子供ができて、考えるようになったことも多くあります。</p>

<p>なによりも、妻への感謝でした。 育児休業で自宅にずっといるのですが、それでも掃除や洗濯・炊事などをしながら子供の面倒を見てくれているわけで、平日に関してはかなりの負担をかけてしまっています。平日はできるだけ早く帰って妻の話を聞いてあげる時間をとったり、休日は家族で気分転換になるよう出かけたりと努力してみましたが、それでもまだ足りないかなと思っています。 子供にとってのお母さんは、お父さんが代わりになることはできないほどの存在に見えます。眠いとき・不安な時などはお母さんにだっこされて授乳しないと落ち着かなかったりします。 それほどに大事な存在だからこそ、適度にリフレッシュしながら毎日楽しく育児をして欲しいと思うわけです。妻はしっかりしている人なので産まれる前は大丈夫かなと思っていたのですが、実際に産まれてから半年くらいするとかなり精神的に参ってきていたようです。時々実家に帰省したり、旅行にいったりしたのは気分転換にはなったようです。 家族として、夫として、妻や子供を支えられるようにならなければと強く思うようになりました。</p>

<p><img src="https://dl.dropboxusercontent.com/u/14531906/hatak.github.io/2012/12/reflesh-300x225.jpg" alt="Refresh" width="300" height="225" class="alignnone size-medium wp-image-17650" /></p>

<p>次に、仕事のことでした。 偶然にも、今年の始めに私の職務内容が変わるチャンスがあり、昨年のような深夜作業・障害対応がメインの仕事ではなくなりました。家庭の生活リズムがつかみにくい時期に仕事のリズムが調整可能であったことはとても運の良いことでした。 一方で、生活の中でしめる仕事の割合の大きさにも気づかされました。時間はもちろん、仕事に関連した生活リズムや夜中のアラートなど、妻だけであれば説明して我慢してもらえるものでも子供の場合は異なってくることもあります。自分の仕事や年齢、家族との生活とのバランスなどを立ち返って考えるきっかけにはなりました。</p>

<h2 id="toc_334">来年に向けて</h2>

<p>今後も子供・家族との時間を大事にできるエンジニアを目指して成長したいと思います。</p>

<p>子供を見ていると、その好奇心の旺盛さと成長の早さにはかなり刺激を受けます。大人が見過ごしてしまうようなものを見つけたり、昨日できなかったことが今日できるようになっていたり。負けじと親も成長しなきゃ、と焦ってしまうことも。 でも、焦りすぎてもダメなんだと思います。離乳食を始めても、いろんな食材を一つずつ、少量から試していってアレルギー反応が出ないことを確認していくのです。そうして積み重ねていけば、大きくなったらいろいろ食べられるようになるのです。</p>

<p><img src="https://dl.dropboxusercontent.com/u/14531906/hatak.github.io/2012/12/github-225x300.jpg" alt="Github" width="225" height="300" class="alignnone size-medium wp-image-17648" /></p>

<p>着実に成長を重ねていって、いつか親子でペアプロするような機会があればいいなと思います。 そうそう、この <a href="http://shop.github.com/products/octocat-onesie">github のロンパース</a> が結構かわいいです。親が好きな服を着せられるのも今のうちかなと思って買ってしまいました。</p>

<p>あまりエンジニア的な話ができずすみません。でも、同じような立場で子育てをされている方の話を聞いてみたい、といつも思っていたので、このような企画に参加できてとてもよかったです。企画してくださった @choplin さんに感謝いたします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RaspberryPi で遊んでみた]]></title>
    <link href="http://blog.hatak.net/2012/11/10/17630"/>
    <updated>2012-11-10T00:00:00+09:00</updated>
    <id>http://blog.hatak.net/2012/11/10/raspberrypi-%e3%81%a7%e9%81%8a%e3%82%93%e3%81%a7%e3%81%bf%e3%81%9f</id>
    <content type="html"><![CDATA[<p>思い立って RaspberryPi を注文したら結構早く手に入ったので、早速遊んでみました。</p>

<p><img src="https://dl.dropboxusercontent.com/u/14531906/hatak.github.io/2012/11/RIMG0067-300x225.jpg" alt="" title="RaspberryPi" width="300" height="225" class="alignnone size-medium wp-image-17634" /></p>

<!--more-->

<p><a href="http://www.raspberrypi.org/">RaspberryPi</a> は、ARMCore プロセッサ搭載の小型基板です。もともと発売開始の頃に買おうとしていたのですが、ただでさえ発送までの時間がかかる上に、販売代理店のサイトで購入中にエラーになってしまってそのままあきらめていたのでした。 ところが、先日 <a href="http://blog.mobilehackerz.jp/2012/10/raspberry-pi10.html">この記事</a> を見て思い出したので、買ってみたわけでした。</p>

<ul>
<li>10/25 : 注文</li>
<li>10/30 : 発送通知メール</li>
<li>11/5 : 到着</li>
</ul>

<p>イギリスからの発送なのでそれなりに時間がかかりますが、それでも元々の代理店よりはかなり早いと思います。値段は £29.99 + £4.99 (送料) の計 £34.98。日本円換算で 4,500 円程度です。</p>

<h3 id="toc_328">組み立て</h3>

<p><a href="https://www.modmypi.com/">ModMyPi</a> は RaspberryPi 専用のカスタムケースなどを取り扱うネットショップです。今回は本体セットを購入したので、本体ボードとケースが送られてきます。が、組み立てというほどではなく載せてはめれば完了です。上下で色を選べるので、上を白、下を青にしてみました。</p>

<p><img src="https://dl.dropboxusercontent.com/u/14531906/hatak.github.io/2012/11/RIMG0061-300x225.jpg" alt="" title="RaspberryPi and iPhone4S" width="300" height="225" class="alignnone size-medium wp-image-17633" /></p>

<p>iPhone と比べると大きさは同じくらいですが、厚さが3倍くらいあります。</p>

<p>あとは OS イメージを書き込んだ SD カードをスロットにいれ、LAN と電源を接続すれば準備完了です。</p>

<h3 id="toc_329">SD カードの準備</h3>

<p>RaspberryPi の公式から OS イメージがダウンロードできます。展開すると 2GB くらいになるので、利用する SD カードは 4GB 以上が推奨されています。今回は手元に余ってた Transcend の SDHC 16GB (Class10) を用意しました。</p>

<p>大容量の SDHC も昔に比べれば値段が安くなっているのでいいですね。</p>

<p>イメージはいくつか種類がありますが、今回はシンプルな ArchLinux を使うことにしました。 SD カードをマウントして書き込めばいいのですが、スクリプトを利用します。Github で公開されているのですが、残念なことに直さないと動きません。 オリジナルのブランチにもいろんな方から PullRequest があるのですが、反映されてない (しかも多すぎてどれが正しいのか分からない) ので、やむを得ず動く状態に直したものを用意しました。</p>

<p><a href="https://github.com/hatak/RasPiWrite">hatak/RasPiWrite · GitHub</a></p>

<p>コロンが抜けてるところと、インデントのおかしな所を直しただけのバージョンです。MacOSX 10.8.2 の python で動作しました。</p>

<p>ローカルに取得した後、スクリプトを起動してウィザードに沿って SD カードへの展開を進めます。mac の SD カードスロットに差し込み、スクリプトを sudo で実行します。</p>
<div class="highlight"><pre><code class="text">$ sudo ./raspiwrite.py
</code></pre>
</div>

<p>これでイメージ完成です。簡単ですね。 スクリプトに sudo が必要なのはマウント周りの操作を行うためかと思いますが、複数ディスクがある場合などは全部フォーマットされてしまう可能性もあるので十分に注意が必要です。</p>

<h3 id="toc_330">起動</h3>

<p>できあがった SD カードを入れ、LAN ケーブルを挿し、電源を挿します。スイッチはないので、電源をつないだら基板の LED がひかり、10秒ほどで起動します。デフォルトは DHCP 取得になっているので、ルータ等で割り当て IP を調べて ssh するのがよさそうです。</p>
<div class="highlight"><pre><code class="text">[root@alarmpi ~]# pacman -Sy
[root@alarmpi ~]# pacman -Syu
[root@alarmpi ~]# uname -a
Linux alarmpi 3.2.27-5-ARCH+ #1 PREEMPT Fri Sep 14 13:23:44 UTC 2012 armv6l GNU/Linux
[root@alarmpi ~]# df -hT
Filesystem Type Size Used Avail Use% Mounted on
rootfs rootfs 1.8G 523M 1.2G 32% /
/dev/root ext4 1.8G 523M 1.2G 32% /
devtmpfs devtmpfs 92M 0 92M 0% /dev
tmpfs tmpfs 92M 0 92M 0% /dev/shm
tmpfs tmpfs 92M 304K 92M 1% /run
tmpfs tmpfs 92M 0 92M 0% /sys/fs/cgroup
tmpfs tmpfs 92M 0 92M 0% /tmp
/dev/mmcblk0p1 vfat 94M 21M 74M 22% /boot
[root@alarmpi ~]# free
total used free shared buffers cached
Mem: 446888 48856 398032 0 9268 20624 -/+
buffers/cache: 18964 427924
Swap: 0 0 0
[root@alarmpi ~]# ps auxf
USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND
root 2 0.0 0.0 0 0 ? S 16:47 0:00 [kthreadd]
root 3 0.0 0.0 0 0 ? S 16:47 0:00 _ [ksoftirqd/0]
root 5 0.0 0.0 0 0 ? S 16:47 0:00 _ [kworker/u:0]
root 6 0.0 0.0 0 0 ? S&lt; 16:47 0:00 _ [cpuset]
root 7 0.0 0.0 0 0 ? S&lt; 16:47 0:00 _ [khelper]
root 8 0.0 0.0 0 0 ? S 16:47 0:00 _ [kdevtmpfs]
root 9 0.0 0.0 0 0 ? S&lt; 16:47 0:00 _ [netns]
root 10 0.0 0.0 0 0 ? S 16:47 0:00 _ [sync_supers]
root 11 0.0 0.0 0 0 ? S 16:47 0:00 _ [bdi-default]
root 12 0.0 0.0 0 0 ? S&lt; 16:47 0:00 _ [kblockd]
root 13 0.0 0.0 0 0 ? S 16:47 0:00 _ [khubd]
root 14 0.0 0.0 0 0 ? S&lt; 16:47 0:00 _ [rpciod]
root 15 0.0 0.0 0 0 ? S 16:47 0:00 _ [kworker/0:1]
root 16 0.0 0.0 0 0 ? S 16:47 0:00 _ [khungtaskd]
root 17 0.0 0.0 0 0 ? S 16:47 0:02 _ [kswapd0]
root 18 0.0 0.0 0 0 ? S 16:47 0:00 _ [fsnotify_mark]
root 19 0.0 0.0 0 0 ? S&lt; 16:47 0:00 _ [nfsiod]
root 20 0.0 0.0 0 0 ? S&lt; 16:47 0:00 _ [crypto]
root 30 0.0 0.0 0 0 ? S&lt; 16:47 0:00 _ [kthrotld]
root 31 0.0 0.0 0 0 ? S&lt; 16:47 0:00 _ [VCHIQ-0]
root 32 0.0 0.0 0 0 ? S&lt; 16:47 0:00 _ [VCHIQr-0]
root 33 0.0 0.0 0 0 ? S&lt; 16:47 0:00 _ [dwc_otg]
root 34 0.0 0.0 0 0 ? S&lt; 16:47 0:00 _ [DWC Notificatio]
root 35 0.0 0.0 0 0 ? S 16:47 0:00 _ [kworker/u:1]
root 36 2.6 0.0 0 0 ? S 16:47 1:59 _ [mmcqd/0]
root 37 0.0 0.0 0 0 ? S 16:47 0:01 _ [jbd2/mmcblk0p2-]
root 38 0.0 0.0 0 0 ? S&lt; 16:47 0:00 _ [ext4-dio-unwrit]
root 82 0.0 0.0 0 0 ? S&lt; 16:47 0:00 _ [bcm2708_spi.0]
root 384 0.0 0.0 0 0 ? S 17:23 0:00 _ [kworker/0:2]
root 28528 0.0 0.0 0 0 ? S 17:54 0:00 _ [flush-179:0]
root 1 0.0 1.2 4596 2396 ? Ss 16:47 0:01 /usr/lib/systemd/systemd --system --deserialize 28
root 46 0.0 0.6 3736 1208 ? Ss 16:47 0:00 /usr/lib/systemd/systemd-udevd
root 50 0.0 1.0 5208 1996 ? Ss 16:47 0:00 /usr/lib/systemd/systemd-journald
root 95 0.0 0.6 2772 1200 ? Ss 16:47 0:00 /usr/sbin/crond -n
root 97 0.0 1.1 6248 2160 ? Ss 16:47 0:00 /usr/sbin/sshd -D
root 163 0.0 1.6 9968 3140 ? Ss 16:49 0:02 _ sshd: root@pts/0
root 165 0.0 0.9 3272 1744 pts/0 Ss 16:49 0:00 _ -bash
root 28579 0.0 0.5 2648 944 pts/0 R+ 18:03 0:00 _ ps auxf dbus 99 0.0 0.7 2808 1396 ? Ss 16:47 0:00 /usr/bin/dbus-daemon --system --address=systemd: --nofork --nopidfile --systemd-activation
root 106 0.0 0.3 1752 676 tty1 Ss+ 16:47 0:00 /sbin/agetty --noclear tty1 38400
root 144 0.0 0.2 1928 516 ? Ss 16:47 0:00 /sbin/dhcpcd -A -q -w eth0 ntp 146 0.0 0.4 3508 792 ? S 16:47 0:00 /usr/sbin/ntpd -s
root 147 0.0 0.3 3676 572 ? Ss 16:47 0:00 /usr/sbin/ntpd -s
root 319 0.0 0.6 2996 1240 ? Ss 17:00 0:00 /usr/lib/systemd/systemd-logind
root 385 0.0 1.5 7076 2900 ? Ss 17:23 0:00 /usr/sbin/syslog-ng -F
</code></pre>
</div>

<p>起動するとこんな感じです。ひとまず pacman でパッケージをアップデートしてあげたら、あとは好みに環境構築すればいいです。 うまく動かなくなったら、また SD カードを作り直せばいいですよね。</p>
<div class="highlight"><pre><code class="text">[root@alarmpi ~]# cat /proc/meminfo
MemTotal: 446888 kB
MemFree: 397924 kB
Buffers: 9300 kB
Cached: 20624 kB
SwapCached: 0 kB
Active: 16772 kB
Inactive: 17684 kB
Active(anon): 4564 kB
Inactive(anon): 168 kB
Active(file): 12208 kB
Inactive(file): 17516 kB
Unevictable: 0 kB
Mlocked: 0 kB
SwapTotal: 1048572 kB
SwapFree: 1048572 kB
Dirty: 12 kB
Writeback: 0 kB
AnonPages: 4528 kB
Mapped: 7264 kB
Shmem: 208 kB
Slab: 11436 kB
SReclaimable: 8652 kB
SUnreclaim: 2784 kB
KernelStack: 384 kB
PageTables: 360 kB
NFS_Unstable: 0 kB
Bounce: 0 kB
WritebackTmp: 0 kB
CommitLimit: 1272016 kB
Committed_AS: 12868 kB
VmallocTotal: 188416 kB
VmallocUsed: 1004 kB
VmallocChunk: 186592 kB
[root@alarmpi ~]# cat /proc/cpuinfo
Processor : ARMv6-compatible processor rev 7 (v6l)
BogoMIPS : 697.95
Features : swp half thumb fastmult vfp edsp java tls
CPU implementer : 0x41
CPU architecture: 7
CPU variant : 0x0
CPU part : 0xb76
CPU revision : 7
Hardware : BCM2708
Revision : 000f
Serial : xxxxxxxxxxxxxxxx
</code></pre>
</div>

<p>とても手軽です。類似のものとしては Openblocks がありますが、桁一つ違うのは大きいですね。 Openblocks が一般的なサーバ機器で、RaspberryPi がパソコンくらいのイメージでしょうか。</p>

<h2 id="toc_331">参考</h2>

<ul>
<li>  <a href="http://blog.mobilehackerz.jp/2012/10/raspberry-pi10.html">MobileHackerz再起動日記: いつまでも届かないRaspberry Piは一手間かけると10日で新型が手に入る</a></li>
<li>  <a href="http://hitoriblog.com/?p=9733"> 約3,300円で買えるLinuxパソコンRaspberry PiをMacで使う | ひとりぶろぐ</a></li>
<li>  <a href="https://wiki.archlinux.org/index.php/Beginners%27_Guide">Beginners&#39; Guide - ArchWiki</a></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis 2.4 -> 2.6 のアップグレード]]></title>
    <link href="http://blog.hatak.net/2012/10/25/17582"/>
    <updated>2012-10-25T00:00:00+09:00</updated>
    <id>http://blog.hatak.net/2012/10/25/redis-2-4-2-6-%e3%81%ae%e3%82%a2%e3%83%83%e3%83%97%e3%82%b0%e3%83%ac%e3%83%bc%e3%83%89</id>
    <content type="html"><![CDATA[<p>Redis 2.6 が正式リリースされました。大きな機能追加に隠れて、いくつかの変更があります。</p>

<ul>
<li>  Lua のサポート</li>
<li>  クライアント接続数の制限解除</li>
<li>  expires のミリ秒対応</li>
</ul>

<p>2.4 以前の config では deprecated になっている設定項目があるため、一部手を入れる必要があります。mac で launchctl を使っている場合、自動起動に失敗していても気づきにくいので注意が必要です。</p>

<!--more-->

<h3 id="toc_325">VirtualMemory</h3>
<div class="highlight"><pre><code class="text">$ redis-server /usr/local/etc/redis.conf
*** FATAL CONFIG FILE ERROR
*** Reading the configuration file, at line 389
&gt;&gt;&gt; &#39;vm-enabled no&#39; Bad directive or wrong number of arguments
</code></pre>
</div>

<p>Virtual Memory (仮想メモリ) の設定は非サポートになっているので、丸ごと削除してしまいます。</p>
<div class="highlight"><pre><code class="text">An overview of new features and changes in Redis 2.6.x
======================================================
...
* Virtual Memory removed (was deprecated in 2.4)
...
</code></pre>
</div>

<p>2.4 以降で depricated になっている下記のプロパティが対象のようです。</p>

<ul>
<li>  vm-enabled</li>
<li>  vm-swap-file</li>
<li>  vm-max-memory</li>
<li>  vm-page-size</li>
<li>  vm-pages</li>
<li>  vm-max-threads</li>
</ul>

<h3 id="toc_326">CONFIG SET parameters</h3>
<div class="highlight"><pre><code class="text">$ redis-server /usr/local/etc/redis.conf
*** FATAL CONFIG FILE ERROR
*** Reading the configuration file, at line 367
&gt;&gt;&gt; &#39;hash-max-zipmap-entries 512&#39; Bad directive or wrong number of arguments
</code></pre>
</div>

<p>2つの設定の設定項目の名称が変更になっています。</p>
<div class="highlight"><pre><code class="text">Migrating from 2.4 to 2.6
=========================
...
The following redis.conf and CONFIG GET / SET parameters changed:

* hash-max-zipmap-entries, now replaced by hash-max-ziplist-entries
* hash-max-zipmap-value, now replaced by hash-max-ziplist-value
...
</code></pre>
</div>

<p>リリースノートを参考にリネームします。</p>

<h2 id="toc_327">参考</h2>

<ul>
<li>  <a href="https://github.com/antirez/redis/blob/2.6/00-RELEASENOTES">redis/00-RELEASENOTES at 2.6 · antirez/redis · GitHub</a></li>
<li>  <a href="http://oldblog.antirez.com/post/redis-2.6-is-near.html">Redis 2.6 is near, and a few more updates</a></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Homebrew で mroonga ストレージエンジンを入れる]]></title>
    <link href="http://blog.hatak.net/2012/10/24/17562"/>
    <updated>2012-10-24T00:00:00+09:00</updated>
    <id>http://blog.hatak.net/2012/10/24/homebrew-%e3%81%a7-mroonga-%e3%82%b9%e3%83%88%e3%83%ac%e3%83%bc%e3%82%b8%e3%82%a8%e3%83%b3%e3%82%b8%e3%83%b3%e3%82%92%e5%85%a5%e3%82%8c%e3%82%8b</id>
    <content type="html"><![CDATA[<p>ローカルマシン (MaxOSX 10.8.2) に MySQL 5.5 + mroonga の環境を構築してたのですが、いろいろ嵌まったのでメモしておきます。</p>

<!--more-->

<h2 id="toc_321">MeCab</h2>

<p>mroonga で TokenMecab トークナイザーを利用するためには MeCab が必要です。 Homebrew で IPA 辞書と合わせてインストールします。</p>
<div class="highlight"><pre><code class="text">$ brew install mecab mecab-ipadic
$ mecab -D
filename: /usr/local/Cellar/mecab/0.994/lib/mecab/dic/ipadic/sys.dic
version: 102
charset: utf8
type: 0
size: 392126
left size: 1316
right size: 1316
$ mecab 今日は雨です
今日 名詞,副詞可能,*,*,*,*,今日,キョウ,キョー
は 助詞,係助詞,*,*,*,*,は,ハ,ワ
雨 名詞,一般,*,*,*,*,雨,アメ,アメ
です 助動詞,*,*,*,特殊・デス,基本形,です,デス,デス
EOS
</code></pre>
</div>

<p>brew で mecab-ipadic 入れるとデフォルトで UTF-8 になるようになっています。mecab コマンドでインタラクティブに形態素解析してみて、文字化けせずに出力されれば問題なしです。</p>

<p>もし、文字化けしてる場合は Homebrew 周りのどこかに問題があります。brew doctor などで調べていきます。</p>
<div class="highlight"><pre><code class="text">$ brew unlink mecab mecab-ipadic
$ brew uninstall mecab mecab-ipadic
$ brew doctor
</code></pre>
</div>

<p>私の場合、10.8 にアップデートする以前に Homebrew で入れた libiconv が中途半端に残ってたことでおかしくなっていたようでした。</p>

<h2 id="toc_322">groonga</h2>

<p>MeCab の次は groonga をインストールします。</p>
<div class="highlight"><pre><code class="text">$ brew install groonga
$ groonga --version
groonga 2.0.7 [darwin12.2.0,x86_64,utf8,match-escalation-threshold=0,nfkc,msgpack,zlib,lzo,kqueue]
configure options: &lt; &#39;--prefix=/usr/local/Cellar/groonga/2.0.7&#39; &#39;--with-zlib&#39; &#39;CC=cc&#39; &#39;CXX=c++&#39; &#39;PKG_CONFIG_PATH=/usr/local/lib/pkgconfig:/usr/local/share/pkgconfig:/usr/local/Library/Homebrew/pkgconfig&#39;&gt;
</code></pre>
</div>

<p>インストール後にチェックをして、TokenMecab が使えるか確認します。 mecab と書かれていない場合は使えません。groonga の configure オプションでは mecab はデフォルト有効と書かれており、mecab-config を自動で探してくれることになっているのですが、パスが通ってないなどがあるのかもしれません。 直接 brew edit で Fomula を書き換えて再度インストールしてしまいます。</p>
<div class="highlight"><pre><code class="text">diff --git a/Library/Formula/groonga.rb b/Library/Formula/groonga.rb
index 1c4e8cf..45a7a2b 100644
--- a/Library/Formula/groonga.rb
+++ b/Library/Formula/groonga.rb
@@ -8,9 +8,11 @@
   depends_on &#39;pkg-config&#39; =&gt; :build
   depends_on &#39;pcre&#39;
   depends_on &#39;msgpack&#39;
+  depends_on &#39;mecab&#39;
+  depends_on &#39;mecab-ipadic&#39;

   def install
-    system &quot;./configure&quot;, &quot;--prefix=#{prefix}&quot;, &quot;--with-zlib&quot;
+    system &quot;./configure&quot;, &quot;--prefix=#{prefix}&quot;, &quot;--with-zlib&quot;, &quot;-with-mecab&quot;, &quot;-with-mecab-config=/usr/local/bin/mecab-config&quot;
     system &quot;make install&quot;
   end
 end
</code></pre>
</div>

<p>これでOK。</p>
<div class="highlight"><pre><code class="text">$ brew install groonga
$ groonga --version
groonga 2.0.7 [darwin12.2.0,x86_64,utf8,match-escalation-threshold=0,nfkc,mecab,msgpack,zlib,lzo,kqueue]
configure options: &lt; &#39;--prefix=/usr/local/Cellar/groonga/2.0.7&#39; &#39;--with-zlib&#39; &#39;--with-mecab&#39; &#39;--with-mecab-config=/usr/local/bin/mecab-config&#39; &#39;CC=cc&#39; &#39;CXX=c++&#39; &#39;PKG_CONFIG_PATH=/usr/local/lib/pkgconfig:/usr/local/share/pkgconfig:/usr/local/Library/Homebrew/pkgconfig&#39;&gt;
</code></pre>
</div>

<h2 id="toc_323">mroonga</h2>

<p>次は mroonga をインストールします。Homebrew には内包されていませんが、mroonga のリポジトリに Fomula があるのでこちらを使います。</p>
<div class="highlight"><pre><code class="text">$ brew install https://raw.github.com/mroonga/Homebrew/master/mroonga.rb --use-Homebrew-mysql
</code></pre>
</div>

<p>もし、MySQL を Homebrew で入れていない場合 (オフィシャルバイナリを利用している場合など) は、同一バージョンのソースを別途ダウンロードして引数に渡します。また、パーミッションの関係で最後の make install で失敗するので、plugin ディレクトリの所有グループを変更してパーミッションも変えておきます。</p>
<div class="highlight"><pre><code class="text">$ sudo chgrp staff /usr/local/mysql/lib/plugin
$ sudo chmod g+w /usr/local/mysql/lib/plugin
$ brew install https://raw.github.com/mroonga/Homebrew/master/mroonga.rb --with-mysql-source=/usr/local/src/mysql-5.5.28 --with-mysql-config=/usr/local/mysql/bin/mysql_config
</code></pre>
</div>

<p>嵌まりながら MySQL を Homebrew 管理とオフィシャルバイナリの両方で試してみたのですが、基本的には Homebrew で揃えた方が便利かなと思いました。</p>

<p>オフィシャルバイナリの特徴をまとめてみるとこんな感じです。</p>

<ul>
<li>長所

<ul>
<li>OS の設定画面で起動/停止、あるいは自動起動設定が行える</li>
<li>インストールウィザードが付属しているためインストールが容易</li>
</ul></li>
<li>短所

<ul>
<li>言語バインディングを利用するときに DYLD_LIBRARY_PATH にパスが通っていないとエラーになることがある 

<ul>
<li>逆にパスを通していると Homebrew でエラーになることがある</li>
</ul></li>
<li>データやログなどのパーミッションがユーザ権限ではなく root になってしまう</li>
<li>起動/停止を行う際にパスワードが必要なのが面倒</li>
</ul></li>
</ul>

<p>個人的には、複数のユーザで利用している mac でユーザ共通に自動起動させたい（もしくはどうしてもオフィシャルバイナリを使いたい）という条件でなければ Homebrew で良いのかなと思いました。</p>

<h2 id="toc_324">動作確認</h2>

<p>MySQL Server が起動していれば、mroonga の Fomula の中でプラグインと関数の追加も行われています。停止していた場合は起動後に追加のコマンドを入力します。</p>
<div class="highlight"><pre><code class="text">$ mysql -uroot -e &#39;INSTALL PLUGIN mroonga SONAME &quot;ha_mroonga.so&quot;; CREATE FUNCTION last_insert_grn_id RETURNS INTEGER SONAME &quot;ha_mroonga.so&quot;; CREATE FUNCTION mroonga_snippet RETURNS STRING SONAME &quot;ha_mroonga.so&quot;;&#39;
</code></pre>
</div>

<p>これで mroonga ストレージエンジンが使えるようになります。</p>
<div class="highlight"><pre><code class="text">root@localhost[test]&gt; SHOW ENGINES;
+-------+---+----------------------+-----+--+----+
| Engine | Support | Comment | Transactions | XA | Savepoints |
+-------+---+----------------------+-----+--+----+
| FEDERATED | NO | Federated MySQL storage engine | NULL | NULL | NULL |
| MRG_MYISAM | YES | Collection of identical MyISAM tables | NO | NO | NO |
| MyISAM | YES | MyISAM storage engine | NO | NO | NO |
| BLACKHOLE | YES | /dev/null storage engine (anything you write to it disappears) | NO | NO | NO |
| CSV | YES | CSV storage engine | NO | NO | NO |
| MEMORY | YES | Hash based, stored in memory, useful for temporary tables | NO | NO | NO |
| mroonga | YES | CJK-ready fulltext search, column store | NO | NO | NO |
| InnoDB | DEFAULT | Supports transactions, row-level locking, and foreign keys | YES | YES | YES |
| PERFORMANCE_SCHEMA | YES | Performance Schema | NO | NO | NO |
| ARCHIVE | YES | Archive storage engine | NO | NO | NO |
+-------+---+----------------------+-----+--+----+
10 rows in set (0.01 sec)

root@localhost[test]&gt; SHOW PLUGINS;
+---------+----+-------+-----+---+
| Name | Status | Type | Library | License |
+---------+----+-------+-----+---+
| binlog | ACTIVE | STORAGE ENGINE | NULL | GPL |
| mysql_native_password | ACTIVE | AUTHENTICATION | NULL | GPL |
| mysql_old_password | ACTIVE | AUTHENTICATION | NULL | GPL |
| CSV | ACTIVE | STORAGE ENGINE | NULL | GPL |
| MEMORY | ACTIVE | STORAGE ENGINE | NULL | GPL |
| MyISAM | ACTIVE | STORAGE ENGINE | NULL | GPL |
| MRG_MYISAM | ACTIVE | STORAGE ENGINE | NULL | GPL |
| ARCHIVE | ACTIVE | STORAGE ENGINE | NULL | GPL |
| BLACKHOLE | ACTIVE | STORAGE ENGINE | NULL | GPL |
| FEDERATED | DISABLED | STORAGE ENGINE | NULL | GPL |
| InnoDB | ACTIVE | STORAGE ENGINE | NULL | GPL |
| INNODB_TRX | ACTIVE | INFORMATION SCHEMA | NULL | GPL |
| INNODB_LOCKS | ACTIVE | INFORMATION SCHEMA | NULL | GPL |
| INNODB_LOCK_WAITS | ACTIVE | INFORMATION SCHEMA | NULL | GPL |
| INNODB_CMP | ACTIVE | INFORMATION SCHEMA | NULL | GPL |
| INNODB_CMP_RESET | ACTIVE | INFORMATION SCHEMA | NULL | GPL |
| INNODB_CMPMEM | ACTIVE | INFORMATION SCHEMA | NULL | GPL |
| INNODB_CMPMEM_RESET | ACTIVE | INFORMATION SCHEMA | NULL | GPL |
| INNODB_BUFFER_PAGE | ACTIVE | INFORMATION SCHEMA | NULL | GPL |
| INNODB_BUFFER_PAGE_LRU | ACTIVE | INFORMATION SCHEMA | NULL | GPL |
| INNODB_BUFFER_POOL_STATS | ACTIVE | INFORMATION SCHEMA | NULL | GPL |
| PERFORMANCE_SCHEMA | ACTIVE | STORAGE ENGINE | NULL | GPL |
| partition | ACTIVE | STORAGE ENGINE | NULL | GPL |
| mroonga | ACTIVE | STORAGE ENGINE | ha_mroonga.so | GPL |
+---------+----+-------+-----+---+
24 rows in set (0.01 sec)

root@localhost[test]&gt; CREATE TABLE diaries (
    -&gt; id INT PRIMARY KEY AUTO_INCREMENT,
    -&gt; content VARCHAR(255),
    -&gt; FULLTEXT INDEX (content) COMMENT &#39;PARSER &quot;TokenMecab&quot;&#39;
    -&gt; ) ENGINE = mroonga COMMENT = &#39;engine &quot;innodb&quot;&#39; DEFAULT CHARSET utf8;
Query OK, 0 rows affected (0.50 sec)

root@localhost[test]&gt; SHOW CREATE TABLE diaries;
+---+--------------------------------------------------------------------------------------+
| Table | Create Table |
+---+--------------------------------------------------------------------------------------+
| diaries | CREATE TABLE `diaries` (
`id` int(11) NOT NULL AUTO_INCREMENT,
`content` varchar(255) DEFAULT NULL,
PRIMARY KEY (`id`),
FULLTEXT KEY `content` (`content`) COMMENT &#39;PARSER &quot;TokenMecab&quot;&#39;
) ENGINE=mroonga DEFAULT CHARSET=utf8 COMMENT=&#39;engine &quot;innodb&quot;&#39; |
+---+--------------------------------------------------------------------------------------+
1 row in set (0.00 sec)
</code></pre>
</div>

<p>warning がでなければ問題なく動作しています。念のため mysql.err や groonga.log といったログにも目を通しておきます。</p>

<p>これで mroonga が使えるようになりました。使ってみた印象としては、文節を考慮してくれる高速な LIKE というイメージです。ちょっとした全文検索であれば、手軽に使えるレベルで良いかと思いました。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[&#8220;Server Manage Deep Talk #1&#8243; の振り返りメモ]]></title>
    <link href="http://blog.hatak.net/2012/10/12/17536"/>
    <updated>2012-10-12T00:00:00+09:00</updated>
    <id>http://blog.hatak.net/2012/10/12/server-manage-deep-talk-1-%e3%81%ae%e6%8c%af%e3%82%8a%e8%bf%94%e3%82%8a%e3%83%a1%e3%83%a2</id>
    <content type="html"><![CDATA[<p>先日、&#8221;<a href="https://www.facebook.com/events/346462502114960/">Server Manage Deep Talk #1</a>&#8221; に参加してきました。</p>

<p>YAPC の懇親会での話がきっかけで @riywo さんに企画していただいたイベントでした。趣旨としては、既成のツールに焦点を絞るのではなく、サーバを効率的（かつ、可能であれば統一的）に管理するにはどうすればいいかというざっくりとした情報交換の場だったのですが、各社の苦悩が感じられてとても面白いものでした。</p>

<p>そのあと、ちょっと自分なりに考えてみたので覚え書きしてみます。</p>

<!--more-->

<p>今回の話を踏まえると、最初に考えなければならないのは大きく2つの点だと思います。 （解釈間違えなどあればご指摘ください。。）</p>

<h3 id="toc_319">「管理」の対象がどこまでなのか</h3>

<p>サーバ管理といっても様々な管理があります。</p>

<ul>
<li>物理と論理

<ul>
<li>物理 : どのデータセンタ/ラック/スロットにあるか</li>
<li>論理 : どのセグメントでどのように利用されているか</li>
</ul></li>
<li>資産と運用

<ul>
<li>資産 : 固定資産の減価償却やリース期間 (業務監査のイメージ)</li>
<li>運用 : どのサービスにどういった用途で利用しているか</li>
</ul></li>
</ul>

<p>このほかにも、オンプレミス/クラウド(VM含)やスペック毎/役割毎など、いろんな分類基準があるわけです。全てをカバーするのも一つの選択肢ですが、ここは目的から軸となる区分を明確化しておく必要がありそうです。 @kentaro さんがおっしゃられていたように、まさに利用シーンの現状や想定を整理した上で、実際どのあたりを吸収するか考える必要があるのだろうと思います。</p>

<h3 id="toc_320">データを集約するか、proxy するか</h3>

<p>@riywo さんのアイディアでは、既存ツールのデータを活かすために Core が欲しいデータを持っている各ツールに問い合わせて返ってきた情報を集約する形になっています。 一方で、@kuwa_tw さんからの意見で全部まとめた箱としてしまうというアイディアもあり、これもありだと思います。</p>

<p>それぞれのメリットを考えてみます。</p>

<ul>
<li>集約式

<ul>
<li>データが一カ所にまとめられる</li>
<li>他サービスへの依存が無い</li>
<li>ここだけ変更すればいい</li>
</ul></li>
<li>proxy式

<ul>
<li>既存ツールはそのままにできる</li>
<li>Core の機能はシンプルに抑えられる</li>
</ul></li>
</ul>

<p>これは現状の利用状況に依るのかも知れないですね。ツールがどの程度(種類・頻度)利用されていて移行のコストがどれくらいかかるのか、あるいは部署を横断的にまとめていくことが社内政治的に可能なのかどうか、そもそも現状のデータをどれくらい Core が吸収できるのか、といったあたりが焦点になる気がします。</p>

<p>私自身の利用経験や環境から考えると、集約してしまう方式が敷居は低そうかなと感じました。連携のために既存ツールに手を入れなければならないのは導入コストとして高くつくかなと。（でも、結局はバランスを見てのハイブリッドになりそう。。）</p>

<p>自分なりにちょっとずつ整理しながら、ひとまずはシンプルなモックを作ってみようかなと思っています。</p>

<p>次回、が行えるようであればさらに掘り下げて、少しでもインフラ担当者が楽になれると幸せですね。 あと、Web サービス事業者だけに限らず、ホスティングなどでまとまった台数を管理していそうな DC 事業者さんとかの話も伺ってみたいと思いました。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[YAPC::Asia Tokyo 2012 で話してきた]]></title>
    <link href="http://blog.hatak.net/2012/09/29/17281"/>
    <updated>2012-09-29T00:00:00+09:00</updated>
    <id>http://blog.hatak.net/2012/09/29/yapcasia-tokyo-2012-%e3%81%a7%e8%a9%b1%e3%81%97%e3%81%a6%e3%81%8d%e3%81%9f</id>
    <content type="html"><![CDATA[<p>9/27-29 の日程で東京大学で <a href="http://yapcasia.org/2012/" title="YAPC::Asia 2012">YAPC::Asia Tokyo 2012</a> が開催されています。 応募したトークを採用していただいたので、スピーカーとして参加させていただきました。</p>

<div style="margin-bottom:5px">
  <strong> <a href="http://www.slideshare.net/idhatak/ss-14499185" title="スマートフォン向けサービスにおけるサーバサイド設計入門" target="_blank">スマートフォン向けサービスにおけるサーバサイド設計入門</a> </strong>
</div>

<!--more-->

<p>諸般の事情でまだサービスリリースがされていないこともあり、かなり概説的な内容となっています。このような場でトークさせていただくのは MySQL Casual に続いて2度目だったのですが、内容が少し分散してしまいまとまりのない感じになってしまったところが反省でした。</p>

<p>YAPC でのスピーカーは一つの目標でした。</p>

<p>はじめて Perl-CGI に触れたのは高校生の頃でした。当時はアクセスカウンタや掲示板のスクリプトでしたが、&#8221;プログラムがホームページで動く&#8221; ということ自体にわくわくしながら見よう見まねでいじってました。大学でもデータ解析やサーバ管理など、何かプログラムを書くときには Perl を使っていました。</p>

<p>その後、社会に出てから改めてオブジェクト指向やモダンな Perl を学びました。サーバ管理などの小さなスクリプトからWebサービスまで、業務で利用してきた期間も5年近くになります。私にとっての Perl はこれまで一番お世話になっているプログラム言語であり、今エンジニアとして仕事をしているのも Perl のおかげだと思っています。</p>

<p>昨年の YAPC::Asia Tokyo 2011 で @lestrrat さんや @941 さんが「来年はないかも知れない」という話をされていたこともあり、開催告知がされた時に応募しようと思っていました。お世話になった Perl を盛り上げたい、何か恩返しにでもなればという思いからでした。</p>

<p>このような思いを踏まえてうまく伝えられなかったなと反省しているのですが、拙い発表を聞いていただいた方の中に一人でも何か新しいこと・今までと違う視点に気づいていただけたならそれで良いのだと自分に言い聞かせています。</p>

<p>年に一度のお祭りですが、参加するたびに自分が Perl を取り巻く文化に魅了されていることに気づかされます。 様々なトークがあり、いろんな視点での意見が交わされているのはとても刺激になりますし、テンションも上がります。この勢いでサービスもうまく形にして、同時に自分自身についてもしっかりと考えていきたいと思いました。</p>

<p>他のトークに優先して聞きに来てくださったみなさま、素敵なカンファレンスを運営してくださっている JPA とスタッフのみなさま、そして多くのスポンサーのみなさま、ありがとうございました！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[テストのために Redis を立ち上げたかった]]></title>
    <link href="http://blog.hatak.net/2012/08/16/15712"/>
    <updated>2012-08-16T00:00:00+09:00</updated>
    <id>http://blog.hatak.net/2012/08/16/%e3%83%86%e3%82%b9%e3%83%88%e3%81%ae%e3%81%9f%e3%82%81%e3%81%ab-redis-%e3%82%92%e7%ab%8b%e3%81%a1%e4%b8%8a%e3%81%92%e3%81%9f%e3%81%8b%e3%81%a3%e3%81%9f</id>
    <content type="html"><![CDATA[<p>ミドルウェアを使った処理のテストでは、テストのための設定でその時限りのデーモンを立ち上げて使いたいものです。 例えば MySQL であれば <a href="https://metacpan.org/module/Test::mysqld">Test::mysqld</a> 、memcached であれば <a href="https://metacpan.org/module/Test::TCP">Test::TCP</a> などを使うことで手軽にデーモンを立ち上げる仕掛けを作ることができます。これを prove にフックさせたりすると、マニュアルでテスト用のデーモンを立ち上げる必要がなくなるという方法がとれます。</p>

<!--more-->

<ul>
<li><a href="http://perl-users.jp/articles/advent-calendar/2011/test/18">テストのためにデーモンを自動的に起動するやりかた2011年版 &#8211; Perl Advent Calendar Japan 2011 Test Track</a></li>
<li><a href="http://blog.riywo.com/2011/12/28/035420">perlbrew+Carton+Amon2+Test::mysqldみたいな &#8211; As a Futurist&#8230;</a></li>
</ul>

<p>Redis を使った処理のテストを書く必要があり、これと同じような方法で立ち上げる設定を作ろうとしました。 デフォルトとは異なるポートで Redis のサーバを立ち上げてあげればいいのですが、redis-server コマンドは起動時の引数で直接ポート指定ができず設定ファイルとして渡す必要があります。ちょっと面倒だな、と思って手抜きをしようと探したところ、<a href="https://metacpan.org/module/Redis">p5-Redis</a> のテストコードの中に目的のものを見つけました。</p>

<ul>
<li><a href="https://github.com/melo/perl-redis/blob/master/t/tlib/Test/SpawnRedisServer.pm">perl-redis/t/tlib/Test/SpawnRedisServer.pm at master · melo/perl-redis · GitHub</a></li>
</ul>

<p>このモジュールを use して、テスト開始時に呼び出して Redis のデーモンを起動、テスト終了後にデーモンを終了してあげればよさそうです。 フレームワークとして Amon2 を使っていたので、t::Util のようなモジュールを作って必要なテストで use してあげるような仕組みでやってみました。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class='perl'><span class='line'><span class="nb">package</span> <span class="nn">t::</span><span class="n">Util</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="k">use</span> <span class="nn">Test::</span><span class="n">SpawnRedisServer</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="k">my</span> <span class="nv">$REDIS</span><span class="p">;</span>
</span><span class='line'><span class="k">use</span> <span class="n">MyApp</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="p">{</span>
</span><span class='line'>    <span class="c1"># start redis-server with Test::SpawnRedisServer (via p5-Redis)</span>
</span><span class='line'>    <span class="nv">$ENV</span><span class="p">{</span><span class="n">REDIS_DEBUG</span><span class="p">}</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'>    <span class="p">(</span><span class="nv">$REDIS</span><span class="p">,</span> <span class="nv">$ENV</span><span class="p">{</span><span class="n">TEST_REDIS</span><span class="p">})</span> <span class="o">=</span> <span class="n">redis</span><span class="p">();</span>
</span><span class='line'>    <span class="k">my</span> <span class="nv">$c</span> <span class="o">=</span> <span class="n">MyApp</span><span class="o">-&gt;</span><span class="k">new</span><span class="p">();</span>
</span><span class='line'>    <span class="nv">$c</span><span class="o">-&gt;</span><span class="n">setup_schema</span><span class="p">();</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="k">END</span> <span class="p">{</span>
</span><span class='line'>    <span class="c1"># stop redis-server</span>
</span><span class='line'>    <span class="nv">$REDIS</span><span class="o">-&gt;</span><span class="p">()</span> <span class="k">if</span> <span class="nv">$REDIS</span><span class="p">;</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="mi">1</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>

<p>$ENV{TEST_REDIS} に格納されるのは &#8220;127.0.0.1:11121&#8243; のような接続先アドレスなので、Redis への接続時に使われるように設定しました。</p>

<p>config はこんな感じ。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='perl'><span class='line'><span class="nb">die</span> <span class="k">unless</span> <span class="p">(</span><span class="nb">defined</span> <span class="nv">$ENV</span><span class="p">{</span><span class="n">TEST_REDIS</span><span class="p">});</span>
</span><span class='line'><span class="o">+</span><span class="p">{</span>
</span><span class='line'>    <span class="s">&quot;Redis&quot;</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span><span class='line'>        <span class="n">server</span> <span class="o">=&gt;</span> <span class="nv">$ENV</span><span class="p">{</span><span class="n">TEST_REDIS</span><span class="p">},</span>
</span><span class='line'>    <span class="p">},</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>

<p>コンストラクタはこんな感じ。(Teng とかとほぼ同じですが。。)</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class='perl'><span class='line'><span class="nb">package</span> <span class="n">MyApp</span> <span class="mf">0.01</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="k">use</span> <span class="n">v5</span><span class="mf">.14</span><span class="p">;</span>
</span><span class='line'><span class="k">use</span> <span class="n">parent</span> <span class="sx">qw/Amon2/</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="k">use</span> <span class="n">Redis</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="k">sub </span><span class="nf">redis</span> <span class="p">{</span>
</span><span class='line'>    <span class="k">my</span> <span class="nv">$self</span> <span class="o">=</span> <span class="nb">shift</span><span class="p">;</span>
</span><span class='line'>    <span class="k">if</span> <span class="p">(</span> <span class="o">!</span><span class="nb">defined</span> <span class="nv">$self</span><span class="o">-&gt;</span><span class="p">{</span><span class="n">redis</span><span class="p">}</span> <span class="p">)</span> <span class="p">{</span>
</span><span class='line'>        <span class="k">my</span> <span class="nv">$conf</span> <span class="o">=</span> <span class="nv">$self</span><span class="o">-&gt;</span><span class="n">config</span><span class="o">-&gt;</span><span class="p">{</span><span class="n">Redis</span><span class="p">}</span> <span class="ow">or</span> <span class="nb">die</span> <span class="s">&#39;missing configuration for &quot;Redis&quot;&#39;</span><span class="p">;</span>
</span><span class='line'>        <span class="nv">$self</span><span class="o">-&gt;</span><span class="p">{</span><span class="n">redis</span><span class="p">}</span> <span class="o">=</span> <span class="n">Redis</span><span class="o">-&gt;</span><span class="k">new</span><span class="p">(</span><span class="nv">%</span><span class="p">{</span><span class="nv">$conf</span><span class="p">});</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>    <span class="k">return</span> <span class="nv">$self</span><span class="o">-&gt;</span><span class="p">{</span><span class="n">redis</span><span class="p">};</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="mi">1</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>

<p>これで無事、テストを走らせるときに一緒に Redis が立ち上がるようになりました。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='perl'><span class='line'><span class="k">use</span> <span class="n">strict</span><span class="p">;</span>
</span><span class='line'><span class="k">use</span> <span class="n">warnings</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="k">use</span> <span class="nn">t::</span><span class="n">Util</span><span class="p">;</span>
</span><span class='line'><span class="k">use</span> <span class="nn">Test::</span><span class="n">More</span><span class="p">;</span>
</span><span class='line'><span class="k">use</span> <span class="n">MyApp</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="k">my</span> <span class="nv">$c</span> <span class="o">=</span> <span class="n">MyApp</span><span class="o">-&gt;</span><span class="n">bootstrap</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="n">is</span><span class="p">(</span><span class="nv">$c</span><span class="o">-&gt;</span><span class="n">redis</span><span class="o">-&gt;</span><span class="n">ping</span><span class="p">,</span> <span class="s">&quot;PONG&quot;</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'><span class="n">done_testing</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>

<p>めでたしめでたし。</p>

<p>と思ったら、ちゃんと <a href="https://metacpan.org/module/Test::RedisServer">Test::RedisServer</a> というモジュールがつくられていました。</p>

<ul>
<li>  <a href="http://unknownplace.org/memo/2012/07/31/1/">Test::RedisServer ってのを書いた &#8211; unknownplace.org</a></li>
</ul>

<p>こちらだと Test::mysqld と同じように書けるのですっきりして見やすそうです。typester++</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[PSGI アプリを supervisord + Server::Starter で動作させる]]></title>
    <link href="http://blog.hatak.net/2012/08/08/14714"/>
    <updated>2012-08-08T00:00:00+09:00</updated>
    <id>http://blog.hatak.net/2012/08/08/psgi-%e3%82%a2%e3%83%97%e3%83%aa%e3%82%92-supervisord-serverstarter-%e3%81%a7%e5%8b%95%e4%bd%9c%e3%81%95%e3%81%9b%e3%82%8b</id>
    <content type="html"><![CDATA[<p>PSGI で動作する Perl の Web アプリをデプロイする環境をどのように作ろうかと思って試してみたので、その手順をまとめてみます。 記事を書きかけて放置してしまっていたので、diff が古かったりするのはご愛敬で。。</p>

<!--more-->

<h2 id="toc_316">構成の概要</h2>

<p>今回構築しようと思う構成は次の通りです。</p>

<ul>
<li>PSGI を用いた簡単な Web アプリ</li>
<li>アプリを動作させる Perl とそのモジュール群は perlbrew + Carton で管理

<ul>
<li>複数のシステムを同一サーバで動かす可能性もあるため分離しておきたい</li>
<li>Carton 使ってみたい</li>
</ul></li>
<li>アプリケーションサーバには Server::Starter + Starman を利用

<ul>
<li>Hotdeploy できるようにするため</li>
</ul></li>
<li>Server::Starter のプロセスは Supervisord で管理</li>
</ul>

<h2 id="toc_317">supervisord の導入</h2>

<p><a href="http://blog.glidenote.com/blog/2011/11/25/install-supervisor/">スーパーサーバーSupervisorの導入手順メモ &#8211; Glide Note &#8211; グライドノート</a> を参考に supervisord を導入します。<br>
今回は CentOS 6 系のサーバで system python に pip 経由でインストールします。 pythonbrew などを利用してシステムと切り離すことも検討したのですが、supervisord を使う目的が OS とアプリの間でプロセス管理をすることなので system python で問題ないと考えました。</p>
<div class="highlight"><pre><code class="text"># setuptools + pip + supervisord のインストール
sudo yum install python-setuptools
sudo easy_install pip
sudo pip install supervisord

# ログ保存用ディレクトリ作成
sudo mkdir /var/log/supervisord/

# 個別設定を格納するディレクトリを作成
sudo mkdir /etc/supervisord.d/

# ベースとなる conf を生成
sudo su - root -c &quot;echo_supervisord_conf &gt; /etc/supervisord.conf&quot;
</code></pre>
</div>

<p>supervisord.conf も前述の記事とほぼ同じですが、umask を CentOS 風にしたいために 002 にしています。<br>
そして、下記のような /etc/init/supervisord.conf を作成した後に <code>initctl start supervisord</code> で起動します。</p>
<div class="highlight"><pre><code class="text">description &quot;supervisord&quot;
start on runlevel [2345]
stop on runlevel [!2345]
respawn exec /usr/bin/supervisord -n
</code></pre>
</div>

<p>supervisord のプロセスが正常に起動していて、ログファイル (/var/log/supervisord/supervisord.log) に正常に出力されていれば OK です。</p>

<h2 id="toc_318">supervisord 用の設定を用意する</h2>

<p>PSGI アプリを supervisord で管理するための設定を用意します。 ここで、環境変数が必要となるのでコマンドラインで調べておきます。</p>

<p>まずは、carton 利用時の perl のサーチパス (@INC) を調べておきます。</p>
<div class="highlight"><pre><code class="text">$ carton exec -I./lib/ -- perl -e &quot;print join(q/:/,@INC)&quot;
./lib/:local/lib/perl5/x86_64-linux:local/lib/perl5:.:/home/hatak/perl5/perlbrew/perls/perl-5.16.0/lib/5.16.0:/home/hatak/perl5/perlbrew/perls/perl-5.16.0/lib/5.16.0/x86_64-linux
</code></pre>
</div>

<p>同様に、今度は $PATH を調べておきます。</p>
<div class="highlight"><pre><code class="text">$ carton exec -I./lib/ -- echo $PATH
/home/hatak/.perlbrew/libs/perl-5.16.0@carton/bin:/home/hatak/perl5/perlbrew/bin:/home/hatak/perl5/perlbrew/perls/perl-5.16.0/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hatak/bin:/home/hatak/bin
</code></pre>
</div>

<p>これらの環境変数を使って、/etc/supervisord.d/sample.ini という設定を書いていきます。 $PATH に加えて、@INC の中身を $PERL5LIB として設定し、直接 supervisord が server_start するようにします。 （server_start する部分を別のスクリプトにしてしまうと、supervisord で restart などの処理を行ってもプロセスが切り離されてしまい、管理から外れてしまう状態になってしまいます）</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='ini'><span class='line'><span class="k">[program:hatak]</span>
</span><span class='line'><span class="na">user</span><span class="o">=</span><span class="s">hatak</span>
</span><span class='line'><span class="na">umask</span><span class="o">=</span><span class="s">002</span>
</span><span class='line'><span class="na">environment</span><span class="o">=</span><span class="s">PERL5LIB=&quot;/home/hatak/www/sample/lib:/home/hatak/www/sample/local/lib/perl5/x86_64-linux:/home/hatak/www/sample/local/lib/perl5:/home/hatak/.perlbrew/libs/perl-5.16.0@carton/lib/perl5/x86_64-linux:/home/hatak/.perlbrew/libs/perl-5.16.0@carton/lib/perl5&quot;,PATH=&quot;/home/hatak/www/sample/local/bin/:/home/hatak/.perlbrew/libs/perl-5.16.0@carton/bin:/home/hatak/perl5/perlbrew/bin:/home/hatak/perl5/perlbrew/perls/perl-5.16.0/bin/&quot;</span>
</span><span class='line'><span class="na">command</span><span class="o">=</span><span class="s">/home/hatak/.perlbrew/libs/perl-5.16.0@carton/bin/carton exec -- /home/hatak/www/sample/local/bin/start_server --port=8080 --path=/tmp/sample.sock --interval=10 --pid-file=/tmp/sample.pid -- /home/hatak/www/sample/local/bin/plackup -s Starman -E deployment --workers=3 --backlog=1024 --max-requests=10000 --preload-app /home/hatak/www/sample/app.psgi directory=/home/hatak/www/sample</span>
</span><span class='line'><span class="na">redirect_stderr</span><span class="o">=</span><span class="s">true</span>
</span><span class='line'><span class="na">stdout_logfile</span><span class="o">=</span><span class="s">/var/log/supervisord/sample.log</span>
</span><span class='line'><span class="na">stdout_logfile_maxbytes</span><span class="o">=</span><span class="s">5MB</span>
</span><span class='line'><span class="na">stderr_logfile</span><span class="o">=</span><span class="s">/var/log/supervisord/sample.err</span>
</span><span class='line'><span class="na">stderr_logfile_maxbytes</span><span class="o">=</span><span class="s">5MB</span>
</span><span class='line'><span class="na">stdout_logfile_backups</span><span class="o">=</span><span class="s">5</span>
</span><span class='line'><span class="na">autorestart</span><span class="o">=</span><span class="s">true</span>
</span><span class='line'><span class="na">startsecs</span><span class="o">=</span><span class="s">5</span>
</span></code></pre></td></tr></table></div></figure>

<p>これで準備は完了です。あとは、supervisord で起動すればおしまいです。</p>
<div class="highlight"><pre><code class="text">sudo supervisorctl add sample
</code></pre>
</div>

<p>少し回りくどい構成のようにも思えますが、ソースをアップロードして server_start のプロセスに -HUP を送ることで Server::Starter がいい感じにプロセスを置き換えてくれます。また、サーバプロセスがなくなったときやサーバ再起動時などには supervisord がサーバプロセスを立ち上げてくれるので、管理も簡単です。</p>

<p>外部からのリクエストは、一度 Nginx などのリバースプロキシで受けて、動的なものだけを PSGI に送りレスポンスを返す形にすると様々な恩恵が受けられそうです。 ただ、今回試した範囲では Nginx から直接 socket に送ることができなかったのでここは今後の課題でした。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[perl で segmentation fault が起きたときの調べかた]]></title>
    <link href="http://blog.hatak.net/2012/06/19/14234"/>
    <updated>2012-06-19T00:00:00+09:00</updated>
    <id>http://blog.hatak.net/2012/06/19/perl-%e3%81%a7-segmentation-fault-%e3%81%8c%e8%b5%b7%e3%81%8d%e3%81%9f%e3%81%a8%e3%81%8d%e3%81%ae%e8%aa%bf%e3%81%b9%e3%81%8b%e3%81%9f</id>
    <content type="html"><![CDATA[<p>サーバを構築した際に嵌まったのでメモしておきます。</p>

<p>CentOS6 系のサーバに perlbrew + Carton で環境を構築していたのですが、一通り構築が終わって plackup すると segmentation fault となってしまったのでした。 /var/log/messages を見てもこんなログばかり。</p>
<div class="highlight"><pre><code class="text">Jun 18 19:28:48 xx-xxxx kernel: app.psgi[2084] general protection ip:322fe17088 sp:49302b8e8cb3704b error:0 in ld-2.12.so[322fe00000+20000]
</code></pre>
</div>

<!--more-->

<p>こんなとき、Perl に coredump を吐かせて gdb で見ることで当たりをつけることができます。</p>
<div class="highlight"><pre><code class="text"># core file size を設定（今回は仮に unlimited に）
limit -c unlimited
# segfault を起こすコマンドを実行
carton exec -- plackup app.psgi
# -&gt; セグフォ
# gdb [実行ファイル] [コアダンプファイル]
gdb `which perl` core.2084
</code></pre>
</div>

<p>こうすることで、gdb のコンソールが表示されます。 あとは where コマンドで関数の呼び出し順序を調べたり、list を使って該当ソースを見たりして当たりをつけましょう。</p>

<p>ulimit で設定していないと core ファイルが生成されないかもしれない、というお話でした。 このような当たりの付け方は Perl に限らず他のプログラムでも同様にできると思います。</p>

<p>ちなみに今回は MySQL-shared のパッケージが足りず、DBD::mysql がうまく入っていなかったためでした。。 local を丸ごと削除して再度 carton install で解決しました。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[vcs_info でプロンプトにリポジトリ名を表示]]></title>
    <link href="http://blog.hatak.net/2012/06/15/14100"/>
    <updated>2012-06-15T00:00:00+09:00</updated>
    <id>http://blog.hatak.net/2012/06/15/vcs_info-%e3%81%a7%e3%83%97%e3%83%ad%e3%83%b3%e3%83%97%e3%83%88%e3%81%ab%e3%83%aa%e3%83%9d%e3%82%b8%e3%83%88%e3%83%aa%e5%90%8d%e3%82%92%e8%a1%a8%e7%a4%ba</id>
    <content type="html"><![CDATA[<p>最近特にターミナルでコードを書くことが増えてきたため、プロンプトでブランチ名であったりそのほかの情報も適宜だせるようにしたいなと設定を調べたり試したりしてみました。</p>

<p>以前までは、bash_completion を利用して表示するということをしていました。.bashrc の例ですが、こんな感じです。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># custom prompt for .bashrc</span>
</span><span class='line'><span class="k">if</span> <span class="o">[</span> -r <span class="s2">&quot;/etc/bash_completion.d/git&quot;</span> <span class="o">]</span>;
</span><span class='line'>    <span class="k">then </span><span class="nv">PS1</span><span class="o">=</span><span class="s2">&quot;[u@h w]$(__git_ps1 &quot;</span><span class="o">(</span>e<span class="o">[</span>0;32m%se<span class="o">[</span>0m<span class="o">)</span><span class="s2">&quot;)$ &quot;</span>
</span><span class='line'><span class="k">fi</span>
</span></code></pre></td></tr></table></div></figure>

<p>これはこれで良いのですが、git でしか利用できません。メインで利用する VCS は git なので問題ありませんが、それ以外の VCS で管理されたコードを読んだりする機会も多々あります。 調べてみたところ、zsh に vcs_info という関数があることを知りました。そこで、これを使ってプロンプトを少し派手にしてみました。</p>

<!--more-->

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># colors</span>
</span><span class='line'>autoload colors;
</span><span class='line'>colors
</span><span class='line'>
</span><span class='line'><span class="c"># vcs_info</span>
</span><span class='line'>autoload -Uz vcs_info zstyle <span class="s1">&#39;:vcs_info:*&#39;</span>
</span><span class='line'>formats <span class="s1">&#39;%f(%F{cyan}%s%f:%F{green}%b%f)&#39;</span>
</span><span class='line'>zstyle <span class="s1">&#39;:vcs_info:*&#39;</span>
</span><span class='line'>actionformats <span class="s1">&#39;%f(%F{cyan}%s%f:%F{green}%b%f|%F{red}%a%f)&#39;</span>
</span><span class='line'>zstyle <span class="s1">&#39;:vcs_info:(svn|bzr):*&#39;</span>
</span><span class='line'>branchformat <span class="s1">&#39;%F{green}%b%f:%F{yellow}r%r%f&#39;</span>
</span><span class='line'>zstyle <span class="s2">&quot;:vcs_info:git:*&quot;</span>
</span><span class='line'>check-for-changes <span class="nb">true </span>zstyle <span class="s2">&quot;:vcs_info:git:*&quot;</span>
</span><span class='line'>stagedstr <span class="s1">&#39;+&#39;</span>
</span><span class='line'>zstyle <span class="s2">&quot;:vcs_info:git:*&quot;</span>
</span><span class='line'>unstagedstr <span class="s1">&#39;-&#39;</span>
</span><span class='line'>zstyle <span class="s1">&#39;:vcs_info:git:*&#39;</span>
</span><span class='line'>formats <span class="s1">&#39;%f(%F{green}%b%f%F{green}%c%F{red}%u%f)&#39;</span>
</span><span class='line'>zstyle <span class="s1">&#39;:vcs_info:git:*&#39;</span>
</span><span class='line'>actionformats <span class="s1">&#39;%f(%F{green}%b%f|%F{red}%a%f%F{green}%c%F{red}%u%f)&#39;</span>
</span><span class='line'>
</span><span class='line'><span class="k">function </span>_precmd_vcs_info <span class="o">()</span> <span class="o">{</span>
</span><span class='line'>    <span class="nv">psvar</span><span class="o">=()</span>
</span><span class='line'>    <span class="nv">LANG</span><span class="o">=</span>en_US.UTF-8
</span><span class='line'>    vcs_info
</span><span class='line'>    psvar<span class="o">[</span>1<span class="o">]=</span><span class="s2">&quot;$vcs_info_msg_0_&quot;</span>
</span><span class='line'><span class="o">}</span>
</span><span class='line'>
</span><span class='line'><span class="c"># add-zsh-hook autoload -Uz add-zsh-hook add-zsh-hook precmd _precmd_vcs_info</span>
</span><span class='line'><span class="c"># prompt setopt prompt_subst local PROMCOL=$&#39;%F{$[1+RANDOM%6]}&#39;</span>
</span><span class='line'><span class="nv">PROMPT</span><span class="o">=</span><span class="s1">&#39;%(?.%F{green}^-^%f.%F{red}@_@%f) &#39;</span><span class="nv">$PROMCOL</span><span class="s1">&#39;%l${WINDOW:+&quot;:$WINDOW&quot;}:%h%F{green}$psvar[1]%f%(!.#.$)&#39;</span>
</span></code></pre></td></tr></table></div></figure>

<ul>
<li>2行目 : 色指定を簡単に行えるようにするため、colors をロードします</li>
<li>5行目 : 今回のテーマである vcs_info をロードします</li>
<li>6-7行目 : 対応する VCS 共通の表示フォーマットを定義します : formats: 通常表示されるフォーマット : actionformats: コンフリクト時などに表示されるフォーマット</li>
<li>8行目 : svn と bzr の時にはリビジョン番号表示をしたいので、フォーマットを定義します</li>
<li>9-13行目 : git の場合の各種設定や専用フォーマットの定義を行っています : check-for-changes: ローカルでの変更があるかチェックをします : staged: &quot;git status&quot; 実行時の &quot;Changes to be committed&quot; があるときには &quot;+&quot; を表示します : unstaged: &quot;git status&quot; 実行時の &quot;Changes not staged for commit&quot; があるときには &quot;-&quot; を表示します</li>
<li>27行目 : プロンプトの表示色をランダムでカラーにします</li>
<li>28行目 : 顔文字はコマンド成否で変化します（<a href="http://smokycat.info/zsh/231">ネタ元</a>）</li>
</ul>

<p>はじめは %1v として <code>$psvar[1]</code> の値をとっていたのですが、カラースキーマがうまくいかないため配列の要素を直指定する形にしています。vcs 管理下にないディレクトリでは <code>$psvar[1]</code> の値は何も入らないため、デザインも崩れません。</p>

<p><img src="https://dl.dropboxusercontent.com/u/14531906/hatak.github.io/2012/06/2012-06-15-2.27.57.png" alt="ターミナルの例" /></p>

<h3 id="toc_315">参考</h3>

<ul>
<li>  <a href="http://d.hatena.ne.jp/holidays-l/20100323/p1">zsh の vcs_info が神！のごとく重かったのですが… : ヒルズで働くholidays-lの技ログ</a></li>
<li>  <a href="http://smokycat.info/zsh/231">zsh 前のコマンドの成否をプロンプトの顔文字で通知 | smokycat.info</a></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MySQL Casual Talks Vol.3 で話してきた]]></title>
    <link href="http://blog.hatak.net/2012/04/20/12428"/>
    <updated>2012-04-20T00:00:00+09:00</updated>
    <id>http://blog.hatak.net/2012/04/20/mysql-casual-talks-vol-3-%e3%81%a7%e8%a9%b1%e3%81%97%e3%81%a6%e3%81%8d%e3%81%9f</id>
    <content type="html"><![CDATA[<p>4/19 にオラクルセンター青山で <a href="http://atnd.org/events/26373" title="MySQL Casual Talks Vol.3">MySQL Casual Talks Vol.3</a> が開催されました。 今回は <a href="http://twitter.com/myfinder" title="@myfinder">@myfinder</a> さんにお声がけいただきトーク枠をいただけたので、挑戦させていただきました。</p>

<div style="width:425px" id="__ss_12602397">
  <strong style="display:block;margin:12px 0 4px"><a href="http://www.slideshare.net/idhatak/mysql-casual" title="MySQL Casual な生活" target="_blank">MySQL Casual な生活</a></strong> <div style="padding:5px 0 12px">
    View more <a href="http://www.slideshare.net/" target="_blank">presentations</a> from <a href="http://www.slideshare.net/idhatak" target="_blank">Hisashi Hatakeyama</a>
  </div>
</div>

<!--more-->

<p>小さな話をいっぱい寄せ集めた内容だったので、うまくまとめきれずすみませんでした。また、時間を気にしてしまって少し早口だったり聞き取りにくかったりした所もあったかと思います。</p>

<p>伝えたかった思いはまとめに集約しています。 何よりも「**MySQL すごいよ、ありがとう**」と言いたかったのでした。MySQL 自体のソフトウェアとしての完成度や開発体制もさることながら、多くのユーザがいて様々な知見・ノウハウが共有されているこの環境自体も大きな資産であると感じています。ない分の動きを把握していて、様々手を加えられるのはとても理想的なことですし憧れます。ですが、そこまでのスキルセットがない人でも、調べたり試したりすることである程度がんばれる、というのが環境含めて完成されている証だと思っています。 また、これは MySQL に限った話ではないのですが、私自身の考えとして実際のサービス運用では様々な視点・知識・経験が必要だと思っています。「何でも屋になろう」ということではなく、「視点を変えてみるとうまくいくんじゃないかな」「そのためには薄くでも知識や経験があると取っつきやすいんじゃないかな」という考えです。サービスを運用していく以上は、使っていただいているユーザさんを「もてなす」心を意識して、そのためにどうすればいいかを考えてメンバーと協力して作り上げていきたいと思っています。</p>

<p>偉そうなことを言いながらも最近は直接のインフラ運用をしていないことも多いのですが、全体としては業務に限らない私自身の経験や思いをまとめたものとさせていただきました。 このような公の場でトークさせていただくのは初めてだったのですが、資料を作る時点で様々追って調べたりまとめたりと、かなり良い勉強となりました。アウトプット大事ですね。 いつもお世話になっているコミュニティに対して、今までは情報を集めて使うだけの立場だったのですが、少しずつ発信・共有する立場にもなりたいというのが今年の目標でした。まだ内容的にも未熟な点が多いと思いますが、人に説明できるまで理解をする（＝自分の言葉でかみ砕く）を重ねていってコミュニティを支えたい・恩返しをしたいと強く思った一日でした。</p>

<p>快適な会場を提供いただいた Oracle のみなさま、とりまとめていただいた運営のみなさま、そしてお集まりいただいて素敵な時間を共有していただいた参加者のみなさま、ありがとうございました。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[レプリケーションが追いつかないときに試すこと]]></title>
    <link href="http://blog.hatak.net/2011/12/07/9407"/>
    <updated>2011-12-07T00:00:00+09:00</updated>
    <id>http://blog.hatak.net/2011/12/07/%e3%83%ac%e3%83%97%e3%83%aa%e3%82%b1%e3%83%bc%e3%82%b7%e3%83%a7%e3%83%b3%e3%81%8c%e8%bf%bd%e3%81%84%e3%81%a4%e3%81%8b%e3%81%aa%e3%81%84%e3%81%a8%e3%81%8d%e3%81%ab%e8%a9%a6%e3%81%99%e3%81%93%e3%81%a8</id>
    <content type="html"><![CDATA[<p>&#8220;<a href="http://mysql-casual.org/2011/11/mysql-casual-advent-calendar-2011.html" title="MySQL Casual Advent Calendar 2011">MySQL Casual Advent Calendar 2011</a>&#8221; 7 日目を担当させていただく、hatak (<a href="http://twitter.com/hisashi" title="@hisashi">@hisashi</a>) です。 普段はモバイルゲームのインフラをメインにみているのですが、今回はそんな業務で経験したことを基に記事を書かせていただきます。 カジュアルすぎる内容かもしれませんが、お付き合いいただければと思います。</p>

<!--more-->

<h2 id="toc_310">MySQL のレプリケーション</h2>

<p>MySQL のレプリケーションは、安定稼働やバックアップ、負荷分散などの目的に利用できる優れた機能です。 bin-log (バイナリログ) を利用して Master サーバから Slave サーバに更新を伝播させ、データの複製を行います。Slave サーバでは、2 つのスレッドが動作しています。</p>

<ul>
<li>IO_THREAD &#8211; Master から送られてきたデータを受け取り、relay-log (リレーログ) として書き出す</li>
<li>SQL_THREAD &#8211; relay-log を読み出し、DB を更新する</li>
</ul>

<h2 id="toc_311">遅延の調べ方</h2>

<p>&#8220;SQL_THREAD&#8221; による遅延の場合は、Slave サーバで &#8220;SHOW SLAVE STATUS&#8221; コマンドを実行することで確認ができます。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hatak@dbslave&gt; SHOW SLAVE STATUS G\
</span><span class='line'>*************************** 1. row ***************************
</span><span class='line'>Slave_IO_State: Waiting for master to send event
</span><span class='line'>Master_Host: 192.168.12.2
</span><span class='line'>Master_User: replicator
</span><span class='line'>Master_Port: 3306
</span><span class='line'>Connect_Retry: 60
</span><span class='line'>Master_Log_File: mysql-bin.012863
</span><span class='line'>Read_Master_Log_Pos: 205295676
</span><span class='line'>Relay_Log_File: mysqld-relay-bin.026640
</span><span class='line'>Relay_Log_Pos: 75468325
</span><span class='line'>Relay_Master_Log_File: mysql-bin.012863
</span><span class='line'>Slave_IO_Running: Yes
</span><span class='line'>Slave_SQL_Running: Yes
</span><span class='line'>Replicate_Do_DB:
</span><span class='line'>Replicate_Ignore_DB:
</span><span class='line'>Replicate_Do_Table:
</span><span class='line'>Replicate_Ignore_Table:
</span><span class='line'>Replicate_Wild_Do_Table:
</span><span class='line'>Replicate_Wild_Ignore_Table:
</span><span class='line'>Last_Errno: 0
</span><span class='line'>Last_Error:
</span><span class='line'>Skip_Counter: 0
</span><span class='line'>Exec_Master_Log_Pos: 205295676
</span><span class='line'>Relay_Log_Space: 205296082
</span><span class='line'>Until_Condition: None
</span><span class='line'>Until_Log_File:
</span><span class='line'>Until_Log_Pos: 0
</span><span class='line'>Master_SSL_Allowed: No
</span><span class='line'>Master_SSL_CA_File:
</span><span class='line'>Master_SSL_CA_Path:
</span><span class='line'>Master_SSL_Cert:
</span><span class='line'>Master_SSL_Cipher:
</span><span class='line'>Master_SSL_Key:
</span><span class='line'>Seconds_Behind_Master: 0
</span><span class='line'>Master_SSL_Verify_Server_Cert: No
</span><span class='line'>Last_IO_Errno: 0
</span><span class='line'>Last_IO_Error:
</span><span class='line'>Last_SQL_Errno: 0
</span><span class='line'>Last_SQL_Error:
</span><span class='line'>Replicate_Ignore_Server_Ids:
</span><span class='line'>Master_Server_Id:100
</span><span class='line'>1 row in set (0.00 sec)</span></code></pre></td></tr></table></div></figure>

<p>ここに示されている &#8220;Seconds_Behind_Master&#8221; の値が、「現在 SQL_THREAD が実行しているクエリの実行時刻」と「Slave サーバが保持しているリレーログの時刻」の差となり、遅延を表しています。</p>

<p>&#8220;IO_THREAD&#8221; による遅延の場合は、Master からのバイナリログが受信しきっていないため、Master における &#8220;SHOW MASTER STATUS&#8221; の結果も参考にする必要があります。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hatak@dbmaster&gt; SHOW MASTER STATUS G\
</span><span class='line'>*************************** 1. row ***************************
</span><span class='line'>File: mysql-bin.012863
</span><span class='line'>Position: 205295676
</span><span class='line'>Binlog_Do_DB:
</span><span class='line'>Binlog_Ignore_DB:
</span><span class='line'>1 row in set (0.00 sec)</span></code></pre></td></tr></table></div></figure>

<p>この結果を基に、どれくらいずれているかを見なければなりません。</p>

<p>Master と Slave で &#8220;File&#8221; と &#8220;Master_Log_File&#8221;、&#8221;Position&#8221; と &#8220;Read_Master_Log_Pos&#8221; をそれぞれ比較し、どの程度転送が遅れているかをチェックします。 &#8220;IO_THREAD&#8221; に起因した遅延の場合は、サーバの処理というよりはネットワーク帯域の問題である可能性が高いと思います。</p>

<p>今回は &#8220;SQL_THREAD&#8221; による遅延を想定してまとめていきます。</p>

<h3 id="toc_312">Master の更新をブロックする</h3>

<p>レプリケーションで送られてくるクエリの流量が多すぎる場合、つまり Master の更新が激しすぎて追いつかないケースでは、そもそも Master での更新を止めてしまうという方法があります。</p>

<p>これは、MASTER_POS_WAIT() 関数を利用することで実現できます。</p>

<p>手順については、<a href="http://dev.mysql.com/doc/refman/5.1/ja/" title="MySQL5.1 リファレンスマニュアル">MySQL5.1 リファレンスマニュアル</a>の FAQ 項目内に「<a href="http://dev.mysql.com/doc/refman/5.1/ja/replication-faq.html#qandaitem-5-4-4-1-4" title="レプリケーションが追いつくまでマスタの更新をブロックする方法">レプリケーションが追いつくまでマスタの更新をブロックする方法</a>」として紹介されています。</p>

<p>この方法では同期化をコントロールすることで追いつかせることができますが、実際にサービス運用中のサーバではなかなか使いづらいところもあります。</p>

<h3 id="toc_313">Slave のパフォーマンスを調整する</h3>

<p>このとき、レプリケーションで伝播するクエリは全て直列化されるため、更新が激しい場合はどうしても遅れてしまうことがあります。 DiskI/O への負荷が高いとき &#8220;innodb-flush-log-at-trx-commit&#8221; の値を変更することで、ディスクへのフラッシュを減らすことができます。このパラメータではログバッファからログファイルへの書き込み、およびディスクへのフラッシュをコントロールすることができます。</p>

<table><thead>
<tr>
<th>設定値</th>
<th>ログバッファのファイルへの書き込み</th>
<th>ディスクへのフラッシュ</th>
<th>備考</th>
</tr>
</thead><tbody>
<tr>
<td>0</td>
<td>毎秒</td>
<td>ログファイル上</td>
<td></td>
</tr>
<tr>
<td>1</td>
<td>コミット時</td>
<td>ログファイル上</td>
<td>デフォルト値</td>
</tr>
<tr>
<td>2</td>
<td>コミット時</td>
<td>毎秒</td>
<td></td>
</tr>
</tbody></table>

<p>この設定値によるパフォーマンス向上度合いは、経験的には効果の大きい順に 0 &gt; 2 &gt; 1 の順と思っています。</p>

<p>my.cnf に記述し起動時に適用することもできますが、 mysqld の再起動をせずに変更・反映が可能です。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">SELECT</span> <span class="o">@@</span><span class="n">innodb_flush_log_at_trx_commit</span><span class="p">;</span>
</span><span class='line'><span class="k">SET</span> <span class="k">GLOBAL</span> <span class="n">innodb_flush_log_at_trx_commit</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>

<p>この設定値はパフォーマンス向上の代わりに、信頼性を犠牲にします。プロセスが突然落ちた場合などにディスクにフラッシュされていないデータをロストする可能性がありますので、状況に応じて（あるいは追いつかせるまでの間だけなど）の使用に抑えることが良いかと思います。</p>

<h2 id="toc_314">まとめ</h2>

<p>MySQL のレプリケーションが追いつかない場合、プロセスの再起動を行わずに簡単に試せて効果の期待できる方法をまとめてみました。</p>

<p>「実践ハイパフォーマンスMySQL」や「エキスパートのためのMySQLトラブルシューティングガイド」などの書籍でもわかりやすく紹介されていますので、ぜひご参照ください。</p>

<p>このほか、サーバ上で不要なデーモン(cpuspeed など)が動いていないかチェックする、ionice(I/O スケジューラを cfq にする必要があります) で mysqld が優先的に DiskI/O を使えるようにするなどサーバ側でもできることはありそうです。</p>

<p>間違っているところや、他にもこんな方法がある、などございましたらぜひお聞かせください。</p>

<p>明日は <a href="http://twitter.com/kamipo" title="@kamipo">@kamipo</a> さんです！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hachioji.pm #11 に行ってきた]]></title>
    <link href="http://blog.hatak.net/2011/12/04/9188"/>
    <updated>2011-12-04T00:00:00+09:00</updated>
    <id>http://blog.hatak.net/2011/12/04/hachioji-pm-11-%e3%81%ab%e8%a1%8c%e3%81%a3%e3%81%a6%e3%81%8d%e3%81%9f</id>
    <content type="html"><![CDATA[<p>町田で行われた hachioji.pm #11 に参加してきました。 前回参加した hachioji.pm が 2 月実施の #2 だったので、9 回ぶり 2 回目の参加でした。振り返れば震災以降ドタバタといろんなことがあって参加できないままだったわけで、ちょっと勿体ないことしたなと反省したりもしてました。</p>

<p>町田も久しぶりすぎて変化に戸惑いが隠せない感じでした。資料作成しようと思ったカフェとかなくなってたし！</p>

<h2 id="toc_308">全体的な感想など</h2>

<p>自己紹介代わりの LT はやっぱりおもしろいと思います。規模が大きくなると難しくなりますが、全員に向かって各々が話す hachioji.pm ならではの雰囲気は好きです。</p>

<p>かなり様々なお話を聞けたことも大きな収穫でした。同時に、モチベーションが上がるような刺激を受けることができました。</p>

<!--more-->

<p>その他、つらつらと思ったことを。</p>

<ul>
<li>ネタが意外とかぶっててなんかずるい &#8211; &#8220;退職しました&#8221; &#8211; &#8220;うれしいこと（内定・転職・おめでた）ありました&#8221; &#8211; &#8220;北海道&#8221;</li>
<li>会場となったお店がよかった &#8211; 屋根裏っぽい雰囲気がよかった &#8211; 料理（とくに鍋）もおいしかった &#8211; オリオンビールが飲みやすかった &#8211; @ytnobody++</li>
<li>業界狭い &#8211; いろんな方とのつながりはやっぱり大事</li>
</ul>

<h2 id="toc_309">MySQL の preload</h2>

<p>LT で話した資料をこちらにおいてあります (PDF 形式です)。 お題の「○○道」でネタを探していたのですが、preload のことで頭いっぱいだったこともありライトな感じにざっとまとめてみました。</p>

<p>周りの方にアドバイスいただいたり、調べたり、試したりしたものを組み合わせた結果、個人的な答えとして今はこのような手法がよいのかなと考えています。ただ、もっと <strike>楽な</strike> 効率のよい方法など、実際に皆さんがどのようにされているかを知りたいなと思っているところです。</p>

<p>幹事の @ytnobody さん、主催の @uzulla さん、そして参加された皆さん、お疲れさま &amp; ありがとうございました。 また次回も都合をつけて参加したいなー。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[YAPC::Asia Tokyo 2011 (2日目) に行ってきた]]></title>
    <link href="http://blog.hatak.net/2011/10/16/6777"/>
    <updated>2011-10-16T00:00:00+09:00</updated>
    <id>http://blog.hatak.net/2011/10/16/yapcasia-tokyo-2011-2%e6%97%a5%e7%9b%ae-%e3%81%ab%e8%a1%8c%e3%81%a3%e3%81%a6%e3%81%8d%e3%81%9f</id>
    <content type="html"><![CDATA[<p>昨日に引き続いて、 <a href="http://yapcasia.org/2011/" title="YAPC::Asia">YAPC::Asia</a> に参加してきました。</p>

<p>個人的な視点で、今回の YAPC から感じた Perl とそれを取り巻く Web サービス系の世界の現状をいくつかまとめると、</p>

<ul>
<li>前回参加した 2 年前に発表された PSGI はもはや標準</li>
<li>プラットフォーマーを中心に大規模サービスのノウハウが溜まってきている</li>
<li>アプリケーションの設計・実装でも、ミドルウェアやハードウェアも含めた視点がより大事になっている</li>
<li>組織が大きくなった会社では、開発者と運用者の良い関係づくり (DevOps の考え方) に取り組んでいる</li>
</ul>

<p>といったところかなと思います。 会社で標準的に使われている開発言語が違っても、根底の考え方や Web サービス系全般での動きは同じだなと痛感しました。</p>

<!--more-->

<hr>

<h2 id="toc_273">続 Unix Programming with Perl</h2>

<p>※講演資料 <a href="http://www.slideshare.net/kazuho/unix-programming-with-perl-2">[No Title]</a> DeNA の kazuho (<a href="http://twitter.com/kazuho">@kazuho</a>) さんの講演。<a href="http://www.slideshare.net/kazuho/unix-programming-with-perl">前回</a>に引き続いて、Unix 環境で正しく動くコードを作るための Tips 紹介のトークでした。Unix の知識が足りずまだ理解が追いついていないので、調べて試さないとと感じた発表でした。</p>

<h3 id="toc_274">正しいコードを書くために</h3>

<ul>
<li>テストだけでは足りない</li>
<li>常に正しく動くコードを書くためには知識が必要 &#8211; Perl の知識 &#8211; OS の知識</li>
</ul>

<h3 id="toc_275">IPC::Open3 によるプロセス間通信</h3>

<ul>
<li>pipe したときにブロックしてしまうケースがある &#8211; 子プロセスが STDIN 待ちになる場合 &#8211; 子プロセスが大量のエラーを吐く場合 &#8212; pipe が制限を持っている &#8212;- MacOSX : 16 Kbyte &#8212;- Linux2.6 : 64 Kbyte</li>
<li>deadlock とならないためには？ &#8211; クローズしてもうまくいかない &#8211; 標準出力全部読んでもうまくいかない &#8211; IPC::Open3 のオプションとして、標準エラー出力に undef いれる &#8211; pipe を使わず temporary file 使えばいい</li>
</ul>

<h3 id="toc_276">Unix signals と race condition (競合状態)</h3>

<ul>
<li>POSIX::pselect &#8211; pselect の外で SIGHUP &#8212; 多くのディストーションでの実装がバグっているため、実際には解決しない &#8211; eval &amp; die &#8212; これでもうまく解決しない &#8211; call syswrite on signal</li>
</ul>

<h2 id="toc_277">まとめ</h2>

<ul>
<li>buffesize は無限大ではない</li>
<li>shell invocation は危険なので system か IPC::Open3 を使う</li>
<li>Unix signals のハンドリングでは競合に気をつける</li>
</ul>

<hr>

<h2 id="toc_278">運用しやすいWebアプリケーションの構築方法</h2>

<p>※講演資料 <a href="http://www.slideshare.net/kazeburo/yapcasia2011">[No Title]</a> Livedoor の kazeburo (<a href="http://twitter.com/kazeburo">@kazeburo</a>) さんの講演。これまでの運用経験を基に、運用しやすい Web アプリケーションとなるためのログや DBI / cache の使い方・Tips をまとめて紹介されていました。確かに、と思うポイントが多く、とても参考になるトークでした。</p>

<h3 id="toc_279">運用しやすいとは？</h3>

<ul>
<li>耐障害性を考慮に入れた設計</li>
<li>アプリケーションからの情報発信</li>
<li>処理単位の明確化</li>
</ul>

<h3 id="toc_280">ログ</h3>

<ul>
<li>「アプリからの情報発信」 &#8211; 障害発生の際に最初に見る &#8211; 障害の検知、原因の特定</li>
<li>適切なログに含まれる情報 &#8211; 時間 &#8211; ログレベル &#8212; 基準を決めて &#8220;DEBUG&#8221;/&#8221;INFO&#8221;/&#8221;WARN&#8221;/&#8221;ERROR&#8221; を使い分ける &#8211; 環境 &#8212; pid や uid、引数など &#8211; caller / stacktrace &#8211; 読み取る人に伝わるメッセージ</li>
<li>Log::Minimal &#8211; 上記の適切なログ基準に沿ってログを出せるようにした &#8211; シリアライズ / カラーリング なども可能</li>
</ul>

<h3 id="toc_281">DBI (SQL)</h3>

<h4 id="toc_282">DB 負荷が急上昇するケース</h4>

<ul>
<li>原因クエリ探す</li>
<li>なんのクエリかアプリで確認</li>
<li>ORM を使っていると調べにくいこともある &#8211; SQL とコードが一致しなく鳴るため、SQL 生成を避けたい</li>
<li>DBIx::Sunny &#8211; caller 情報を SQL に埋込みクエリコメントにできる &#8211; SQL::Maker と組み合わせて利用できる</li>
</ul>

<h4 id="toc_283">接続が滞留するケース</h4>

<ul>
<li>最大接続数に達して接続エラー &#8211; メンテナンス時に timeout まで待つ &#8211; SHOW INNODB STATUS が見れない</li>
<li>接続滞留対策 &#8211; Scope::Container &#8212; DB 接続部の処理単位を短く、わかりやすく &#8211; Scope::Container::DBI &#8212; 上記を簡単に実現するために便利機能を追加したモジュール</li>
</ul>

<h3 id="toc_284">cache / memcached</h3>

<ul>
<li>課題 &#8211; Session::Store::Memcached &#8212; 簡単で高速、Expires 処理も自動化できる &#8212; 一方でストレージ永続性がないのは困ることもある &#8211; 特定キャッシュへの集中 &#8212; 分散アルゴリズム上でも特定サーバに集中してしまうことがある &#8211; cache thundering herd problem &#8212; memcache 上で exipre した瞬間に DB にアクセスが集中してしまう</li>
<li>Cache::Memcached::IronPlate &#8211; 冗長して保存することで cache の冗長性確保 &#8211; cache の負荷分散も行える</li>
<li>Cache::Isorator &#8211; ゆっくり expire させることができる</li>
</ul>

<h3 id="toc_285">Metrics</h3>

<ul>
<li>プロセスのステータスを取得できるようにしてグラフ化する &#8211; Plack::Middleware::ServerStatus::Lite &#8211; Parallel::Scoreboard</li>
</ul>

<h3 id="toc_286">まとめ</h3>

<ul>
<li>耐障害性を考慮に入れた設計 &#8211; cache &#8211; memcached</li>
<li>アプリケーションからの情報発信 &#8211; DBI &#8211; ログ &#8211; Metrics</li>
<li>処理単位の明確化 &#8211; DBI connection</li>
</ul>

<hr>

<h2 id="toc_287">watch your log</h2>

<p>DeNA の nekokak (<a href="http://twitter.com/nekokak">@nekokak</a>) さんの講演。社内 DevOps の観点から基準を決めてログ出力し、それを監視するためのツールを作成したというお話。&#8221;DevOps&#8221; と &#8220;ログ監視&#8221; については各社でかなり試行錯誤しているところかもしれません。 ログ監視は最近色々考えていて自分で実装しようかなと思っているところだったので、Komainu も試してみます。あと、「必要に応じたエンジニアリング」というスタンスはいいなと思います。</p>

<h3 id="toc_288">DevOps</h3>

<ul>
<li>Dev と Ops 相互に協力する事が必要 &#8211; 自社 Dev は運用を考えられなければならない &#8211; 自社 Ops は Dev から渡される運用を丸受けしてはダメ</li>
<li>Dev Ops の垣根取り払って密なコミュニケーションを</li>
<li>運用を考えられる Dev &#8211; 障害は一次対応が Ops のことが多い &#8211; 運用したことないミドルウェアを導入する場合は、事前に互いに調べて共有 &#8211; 仕様変更 / 新機能のリリースタイミングで共有を行う</li>
<li>丸受けしない Ops &#8211; サービス仕様・アーキテクチャを理解 &#8211; 障害発生時に何を対応する必要があるか理解 &#8211; 必要な情報は Dev に提出 &#8211; 「お母さん役みたいなもの」</li>
</ul>

<h3 id="toc_289">コミュニケーション濃度の問題</h3>

<ul>
<li>お互いしっかりコミュニケーション取る</li>
<li>コミュニケーションもレベル・粒度ある</li>
<li>「お互い言い分あるだろうが gdgd 言う前に行動しろ」</li>
</ul>

<h3 id="toc_290">障害そして監視</h3>

<ul>
<li>障害検知の仕組みとして監視必要 &#8211; 死活監視 &#8211; リソース監視 &#8211; ログ監視</li>
</ul>

<h3 id="toc_291">ログ</h3>

<ul>
<li>お互いで取り決めたフォーマットに沿ったログ出力 &#8211; Dev と Ops が面倒みるにあたって取り決めるといい</li>
<li>accesslog / errorlog &#8211; 監視する項目の取り決めをしておく &#8211; ステータスコード監視でサービスがどのような状況か分かる</li>
<li>applog (syslog) &#8211; フォーマットの取り決めが重要なところ &#8211; 障害レベルの分類をログレベルで出力するなどの取り決め &#8212; 携帯にメールか、会社のメールかでレベルか</li>
<li>mysql slow log &#8211; だいたいボトルネックは DB のことが多い</li>
<li>ログ収集方法 &#8211; ログを良い感じで監視できるソリューションがない</li>
</ul>

<h3 id="toc_292">Komainu</h3>

<ul>
<li>設定に応じて集計 &#8211; accesslog 集計 &#8211; applog 集計 &#8211; mysql slow log 集計</li>
<li>アーキテクチャ &#8211; fork model &#8211; notify は IRC と Email &#8211; データは database に保存 &#8212; サマリ集計し、前回からどれくらい増えたか知りたい &#8212; グラフ化する &#8212; プロセス間通信せずにデータを受け渡す</li>
<li>何が重要か &#8211; サービスクオリティ維持のため &#8211; 利用者からの問い合わせベースで障害に気づくのは情けない &#8211; 攻めの運用 &#8211; ログ情報を通知することでエラーに向きあう</li>
</ul>

<h3 id="toc_293"><strong>Shut the fuck up and write some code</strong></h3>

<ul>
<li>行動こそすべて</li>
<li>誰かが始めないと何も始まらない</li>
<li>問題意識を持った人が率先して行動 &#8211; コードの良し悪しなどはどうでもいい</li>
</ul>

<hr>

<h2 id="toc_294">Managing A Band Of Hackers</h2>

<p>DeNA の hidek (<a href="http://twitter.com/hidek">@hidek</a>) さんの基調講演。Perl ハッカーを束ねるマネージャーとしての考え方や経験のお話でした。 とてもいい話でした。DeNA には優秀で著名な方が集まっているイメージがありますが、このようなコミュニティというか、仲間の魅力が根底にはあるのだろうなと感じる内容でした。途中、何度もチームを褒めているところが、率直に褒めているように感じられて印象的でした。</p>

<h3 id="toc_295">management</h3>

<ul>
<li>なぜマネージャーが必要？ &#8211; 一人では規模の限界</li>
<li>集団で物事を作るということ &#8211; バラバラに動くと個人個人のプレーになってしまう &#8211; 誰かが指揮する &#8211; これがマネージャー</li>
<li>&#8220;The whole is more than the sum of its parts.&#8221; &#8211; 1 + 1 が 2 以上になるようにしなければならない</li>
</ul>

<h3 id="toc_296">tasks of the manager</h3>

<ul>
<li>マネージャーの業務にはエンジニアとしての経験が必要 &#8211; 大規模なほど広いレイヤの知識が必要</li>
</ul>

<h4 id="toc_297">project management</h4>

<ul>
<li>プロダクトのライフサイクルを維持する &#8211; エンジニアリング未経験だと無理</li>
<li>計画を立てる</li>
<li>開発中の進捗・マイルストーン管理</li>
</ul>

<h4 id="toc_298">personal matters</h4>

<ul>
<li>人事も大事</li>
<li>採用面接 &#8211; 見極める力が求められる</li>
<li>配属 &#8211; 仕事を与えるということ &#8211; その人の持ってる力などを見極めることが大切 &#8211; コミュニケーション能力も必要 &#8212; その人が何をしたいのかを聞く</li>
<li>評価 &#8211; どんな仕事をしたか、を見るためにもエンジニア経験が必要</li>
</ul>

<h4 id="toc_299">etc</h4>

<ul>
<li>事務仕事</li>
<li>会議 &#8211; 無駄なものもあるが、最近必要と感じることもある &#8212; 海外支社とのテレビ会議など、図を書いたりすることで理解が早くなる &#8211; Face to Face も重要</li>
</ul>

<h3 id="toc_300">the manager of hackers</h3>

<ul>
<li>少しとんがった人たちのマネージャーとして</li>
<li>Platform System Group &#8211; プロジェクト開始時は 3 名、現在 20 名 &#8211; CPAN Author が 6 名</li>
</ul>

<h4 id="toc_301">hackers はどういう人達か</h4>

<ul>
<li>&#8220;no man is an island&#8221; &#8211; 一人だと寂しくて死んじゃう</li>
<li>get bored easily &#8211; 飽きっぽい &#8211; 餌を与え続ける</li>
<li>priority &lt; interest &#8211; つまらない仕事を与えつつも、先に楽しい仕事を用意しておく</li>
<li>late morning, late nite &#8211; 働いている時間は一緒 &#8211; 裁量労働なので良いが、相談したいときにいつ来るかわからないのは困ることも</li>
<li>KY &#8211; 読めない事自体は仕事に影響しないので、悪いことではない &#8211; 悪ノリする</li>
</ul>

<h3 id="toc_302">what should I do ?</h3>

<ul>
<li>これはハッカーのマネージャーだけでなく、一般でも通じるところはある</li>
</ul>

<h4 id="toc_303">delegation</h4>

<ul>
<li>仕事を任せる &#8211; 失敗もするけど、任せると成長する</li>
<li>自分でやっちゃおう、と思うこともある</li>
<li>「任せる」と「丸投げ」は違う &#8211; 任せるための準備はする &#8211; バックアッププランは作る &#8211; 失敗したらマネージャーが責任を持つ</li>
</ul>

<h4 id="toc_304">bad news first</h4>

<ul>
<li>悪い報告を先にするようにしてもらう</li>
</ul>

<h4 id="toc_305">TMTOWTDI</h4>

<ul>
<li>やり方は一つではない &#8211; これはマネジメントだけではない</li>
<li>多様性を許容する</li>
</ul>

<h3 id="toc_306">マネージャが少ない会社は大変</h3>

<ul>
<li>マネージャは優秀なエンジニアじゃないとできない &#8211; 選択肢として考えて欲しい</li>
</ul>

<h3 id="toc_307">コミュニティに参加して欲しい</h3>

<ul>
<li>技術的な刺激を受けられる</li>
<li>人脈を作る &#8211; マネージャとして重要 &#8211; 最終的には経験の糧になる</li>
</ul>

<hr>

<p>このほか、LT なども面白く刺激的なものが多く、とても良いカンファレンスでした。</p>

<p>次回がどのようになるかはまだ未定とのことでしたが、次回が YAPC::Asia どこで行われても参加したいと思っています。同時に、これまではカンファレンスやセミナーに参加しつつもずっと聞く側でしたが、今後は YAPC に限らず、もっとコミュニティ全般に対して積極的に貢献できる活動をしたいと思った 3 日間でした。</p>

<p>発表者、スタッフ、参加者、そしてスポンサー企業のみなさま、お疲れ様でした。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[YAPC::Asia Tokyo 2011 (1日目) に行ってきた]]></title>
    <link href="http://blog.hatak.net/2011/10/15/6689"/>
    <updated>2011-10-15T00:00:00+09:00</updated>
    <id>http://blog.hatak.net/2011/10/15/yapcasia-tokyo-2011-1%e6%97%a5%e7%9b%ae-%e3%81%ab%e8%a1%8c%e3%81%a3%e3%81%a6%e3%81%8d%e3%81%9f</id>
    <content type="html"><![CDATA[<p>Perl のおまつり、 <a href="http://yapcasia.org/2011/" title="YAPC::Asia">YAPC::Asia</a> に参加しています。<br>
昨年はプライベートでドタバタしていたので、2 年ぶりの参加でした。前回に比べて参加者も多く、それでいてスムーズなイベント進行と素敵なトークの数々でとても楽しい時間を過ごしています。 ひとまず 1 日目を振り返りつつ、聞いたトークをまとめておこうと思いました。</p>

<p>振り返ると、インフラ寄りな内容を選んでいたこともありますが、今日は Perl に限らない話も多かったように思います。それだけ広い知識と経験が必要で、いろんな所でいろんなひとが挑戦していることがわかってわくわくしましたが！</p>

<!--more-->

<hr>

<h2 id="toc_242">Perl 5.16 and beyond</h2>

<p>今回のスペシャルゲスト、 Perl5 開発リーダーの Jesse Vincent (<a href="http://twitter.com/obra">@obra</a>) さんの講演。Perl5 の開発プロセスがどのように変化してきたか、そして今後の Perl5 がどうなっていくのかというお話でした。 （英語のセッションだったので内容を頭の中で理解するのが追いつかずメモ取りきれなかったので間違えていたら指摘をお願いします。。）</p>

<h3 id="toc_243">Pumpking</h3>

<p>Perl5 の開発体制が整ってきたのでリリーススパンが早くなってきた。</p>

<ul>
<li>VCS を Git に変えた</li>
<li>リリースをコミッタの持ち回りに</li>
<li>約 1 年で 5.12 → 5.14 そして Perl 開発マネージャーとしての仕事についての説明。</li>
<li>Perl5 の方向性を決める</li>
<li>開発メンバーにタスクを振る</li>
<li>仕様に関する文書をまとめる つまり <strong>&#8220;You make Perl&#8221;</strong></li>
</ul>

<h3 id="toc_244">Vision</h3>

<p>&#8220;New version should not break old environment&#8221; と &#8220;Perl should run everywhere&#8221;</p>

<ul>
<li>互換性を重視しつつ、進化は続ける</li>
<li>use でバージョンを指定した場合はその指定されたバージョンの挙動に合わせる &#8211; 古い文法には極力沿うようにする &#8211; 指定されたバージョンよりも新しい機能は動かないようにする</li>
</ul>

<p>そして機能をシンプルにして、仕様を明確化させる。</p>

<ul>
<li>Core の機能をモジュールとして分割する &#8211; &#8220;traditional&#8221; と &#8220;bootstrappable&#8221; の 2 種類のエディションに</li>
<li>別の言語でも再実装できるように &#8211; 生き残るために</li>
</ul>

<hr>

<h2 id="toc_245">Webアプリケーション高速化</h2>

<p>※講演資料 <a href="http://ma.la/files/yapcasia2011/#0">YAPC::Asia 2011 / 高速化のはなしとか</a> ライブドアの mala (<a href="http://twitter.com/bulkneets">@bulkneets</a>) さんの講演。すべてを聞いたあとの「気持よく書ける範囲で最適化」というまとめに納得しました。先回りしてキャッシュしておく戦略は難しそうですが、効果は大きそうなのでやってみたいと思っています。</p>

<h3 id="toc_246">はじめに</h3>

<ul>
<li>チューニングについてのスタンス &#8211; 努力だけでどうにもならないときは、卑怯な手段を使う &#8211; バレなきゃイカサマではない</li>
<li>方法はいろいろ &#8211; 頑張って高速化する「努力」 &#8211; そもそも処理しない「Hack」 &#8211; SSD など「財力」</li>
<li>どの方法を選ぶかはケースバイケース &#8211; 適切な手段を選ぶことは必要 &#8211; ハードウェアはすごく早くはならない</li>
</ul>

<h3 id="toc_247">一般的な方法</h3>

<ul>
<li>ボトルネックを見つけてチューニング &#8211; リソースやスロークエリ等の監視 &#8211; プロファイリング &#8212; Devel::NYTProf / Devel::KYTProf &#8212; 計測用のスクリプトを作成しておく &#8212;- Shell::Perl が便利 &#8212; stopwatch で時間計測 &#8212;- benchmark だと CPU 時間を計測する &#8212;- 1 req の処理時間を測って感覚を把握できるようにする</li>
<li>キャッシュや静的生成 &#8211; バックエンドに飛んだら負け &#8212; PSGI でも 数千 req/sec しかさばけない &#8212; Nginx などの静的レスポンスなら 数万 req/sec &#8211; 状況に応じてキャッシュを選択する &#8212; データ量・更新頻度・揮発性 &#8212; データ型サポート &#8212; 複数処理で使いまわすか</li>
<li>コード &#8211; テクニックを抑えておく &#8212; 必要なデータはまとめて引いておく &#8212; 遅延評価 &#8212; MySQL では &#8220;WHERE IN&#8221; / &#8220;BULK UPDATE&#8221; の活用 &#8212; memcached では &#8220;get_multi&#8221; を使ってプロトコルオーバヘッド減らす</li>
</ul>

<h3 id="toc_248">あまり真似されない方法</h3>

<h4 id="toc_249">Bloom Filter</h4>

<ul>
<li>KVS / MySQL への問い合わせ前に大雑把なクエリを間引く &#8211; 精度はデータ量とのトレードオフ &#8211; &lt;a href=&#8221;<a href="http://fallabs.com/blog-ja/promenade.cgi?id=70">http://fallabs.com/blog-ja/promenade.cgi?id=70</a></li>
<li>存在しないキーを大量に問い合わせるケースで有効 &#8211; ブックマークのカウンタ &#8211; ブラウジング履歴調べる &#8211; 富豪的クエリ</li>
<li>memcached への問い合わせなどでネガティブキャッシュを減らせる</li>
<li>使うのは CPU &#8211; パラメータにも依るが 数万 qps 処理できる &#8211; ハッシュよりは遅く、リモートの DB よりは早い</li>
</ul>

<h4 id="toc_250">Cache warmup</h4>

<ul>
<li>よく使われるデータを先に載せておく &#8211; MySQL innodb &#8211; memcached</li>
<li>ユーザがページを表示した瞬間に id を Q4M に入れる &#8211; worker が先回りしてキャッシュに入れる</li>
<li>ライトスルー方式との違い &#8211; 参照されそうなときに乗るのでヒットしやすい &#8211; キャッシュ生成がレスポンス生成より遅いと重くなる</li>
</ul>

<h4 id="toc_251">Varnish + ESI</h4>

<ul>
<li>最近流行りの構成は Nginx + Standalone PSGI でいい</li>
<li>Varnish が使えるポイント &#8211; 高速化 &#8211; vcl で書ける &#8211; ESI が使える &#8212; Akamai が開発した SSI のような仕組み</li>
<li>ESI を使うとパーツごとにキャッシュできる &#8211; 利点 &#8212; フロントとバックエンド間の転送量節約できる &#8211; 問題点 （主に v2） &#8212; Varnish が Contents-Length 返してくれない &#8212; Varnish が ETag みてくれない &#8212; メモリが足りなくなくなると重くなる</li>
</ul>

<hr>

<h2 id="toc_252">新はてなダイアリーの裏側</h2>

<p>はてなの大西 (<a href="http://twitter.com/yasuhiro_onishi">@yasuhiro_onishi</a>) さんの講演。はてなダイアリーが &#8220;Hatena Blog&#8221; にリニューアルを解説するセッションでした。主に表示に関わる仕様変更をユーザの行動に影響しないようにするため、様々な工夫をされているのですね。。</p>

<h3 id="toc_253">技術的な話</h3>

<ul>
<li>外部ドメイン化 / JS フリー化 &#8211; 従来ははてな共通ドメイン・ログインクッキー &#8211; 利点 &#8212; どのサービスでもログイン状態になれる &#8212; 編集 / 閲覧の区別がない &#8211; 欠点 &#8212; XSS 脆弱性に弱いので自由に JS 書けない</li>
<li>クロスドメイン通信 &#8211; ヘッダを iframe 化することでログイン時のメニューを表示</li>
<li>フィードバックシステム &#8211; iframe で表示するヘッダに設置する &#8211; 運営への意見をフィードバックする際に、ユーザがどのページにいるかを一緒に送れる</li>
<li>アクセスコントロール &#8211; ユーザの自由な認証設定に応じていきたい &#8212; 一方で認証の仕組みが複雑になってしまう &#8211; ブログごとに閲覧用 cookie を発行することで対応</li>
<li>はてな記法++ &#8211; ブラケットを [.. から &lt; ..&gt; に変更 &#8212; タグとして解釈可能となり style 属性付与ができたりする</li>
<li>キャッシュ戦略 &#8211; なるべく外側でキャッシュする &#8211; キャッシュに依存しない作りにする &#8211; 基本はページまるごとキャッシュ</li>
</ul>

<hr>

<h2 id="toc_254">Webアプリでパスワード保護はどこまでやればいいか</h2>

<p>「<a href="http://www.amazon.co.jp/%E4%BD%93%E7%B3%BB%E7%9A%84%E3%81%AB%E5%AD%A6%E3%81%B6-%E5%AE%89%E5%85%A8%E3%81%AAWeb%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%81%AE%E4%BD%9C%E3%82%8A%E6%96%B9-%E8%84%86%E5%BC%B1%E6%80%A7%E3%81%8C%E7%94%9F%E3%81%BE%E3%82%8C%E3%82%8B%E5%8E%9F%E7%90%86%E3%81%A8%E5%AF%BE%E7%AD%96%E3%81%AE%E5%AE%9F%E8%B7%B5-%E5%BE%B3%E4%B8%B8-%E6%B5%A9/dp/4797361190">安全なWebアプリケーションの作り方</a>」の著者、徳丸浩 (<a href="http://twitter.com/ockeghem">@ockeghem</a>) さんの講演。同本の 5.1 章を解説する流れで説明されていましたが、RainbowTable などの説明がとてもわかり易かったです。</p>

<h3 id="toc_255">本日のテーマ</h3>

<p><strong>単に HASH 化しただけでは元に戻せるのか？</strong> - クラックは 2 種類 &#8211; オンラインクラック : リモートからのパスワード試行 &#8211; オフラインクラック : 情報を盗み、攻撃者の手元で平文パスワードを求める - パスワードだけ保護する理由とは？ &#8211; パスが漏れてれば他の個人情報も漏れている &#8211; パスワードを使いまわす利用者もいる &#8211; パスワード保護は運営者の義務</p>

<h3 id="toc_256">オンラインクラック</h3>

<ul>
<li>パターン &#8211; 総あたり攻撃 : 時間かかるのであまりやらない &#8211; 辞書攻撃 : 辞書のものを順にパスワードとして試行 &#8211; その他のバリエーション &#8212; ジョーアカウント探索 : ID と pass を同じにしているものを総あたりで試行 &#8212; 逆総当り攻撃 : パスワード固定でユーザを変える &#8212;- 普通の総当りに比べて成功確率高い &#8212;- Twitter のような ユーザ ID がわかっているようなものは特に</li>
<li>対策 &#8211; 強いパスワードを付けてもらう &#8211; アカウントロックが基本 &#8211; ジョーアカウントは登録時にチェック &#8211; 逆総あたり対策として、辞書のものは NG にする</li>
</ul>

<h3 id="toc_257">オフラインクラック</h3>

<ul>
<li>なぜ暗号化ではなくハッシュなの？ &#8211; 暗号化は鍵管理が難しいが、ハッシュは鍵管理が不要</li>
<li>ハッシュは安全？ &#8211; 一般的にはハッシュ値から平文を「復元する」ことはできない &#8211; パスワードの場合は特別な事情がある &#8212; 短い文字列 &#8212; 文字種限られている</li>
<li>ハッシュから平文に戻す方法 &#8211; 総当たり攻撃・辞書攻撃 &#8212; オフライン型のパスワードクラックツール &#8212;- GPU 高速化に伴ってかなり高速にできるようになった &#8211; RainbowTable &#8212; 逆引き表 + 還元関数でチェーンを作る &#8212;- 単純な逆引き表は膨大なデータ量 &#8212;- 圧縮するために還元関数を使う &#8212; チェーンの「先頭」と「末尾」だけ保存すればいい &#8212; 探索はハッシュに還元関数をかけていって「末尾」と一致するかどうかを見ればいい &#8212;- 一致したらその「先頭」がパスワード &#8212; どのアルゴリズムでも実現できる &#8212;- アルゴリズム特有の脆弱性を使っていない &#8211; Salt &#8212; ハッシュの元データに追加する文字列 &#8212;- 見かけのパスワードの長さを長くする &#8212; ユーザごとにソルトを変えることでパスワードが同じでも異なるハッシュ値を得られる &#8211; Streching &#8212; ハッシュの計算を繰り返ことで、ハッシュ計算を遅くする &#8212; メリット／デメリットある</li>
</ul>

<h2 id="toc_258">パスワードの暗号化は本当に無理か</h2>

<ul>
<li>HSM (Hardware Security Module) ならばいける &#8211; 復号化機能を無効にできればよい</li>
</ul>

<hr>

<h2 id="toc_259">Perl で構築された中規模サイトの DC 引っ越し記録</h2>

<p>※講演資料 &lt;a href=&#8221;<a href="http://dl.dropbox.com/u/224433/YAPC2011/index.html">http://dl.dropbox.com/u/224433/YAPC2011/index.html</a> KAYAC の sfujiwara (<a href="http://twitter.com/sfujiwara">@sfujiwara</a>) さんの講演。&#8221;こえ部&#8221; をレンタルサーバから自社インフラに移設した時のまとめを紹介されていました。アップロードデータのあるサービスで新しいファイルを旧環境でケアしてあげる方法は難しそうですが、Nginx の効率のよい使い方などは参考になりました。</p>

<h3 id="toc_260">こえ部 &amp; システム概要</h3>

<ul>
<li>音声投稿共有サイト</li>
<li>機能 &#8211; flash + kamaitachi でブラウザからその場で録音 &#8211; メール添付 &#8211; &#8220;こえ部 Live!&#8221; は Red5 + AnyEvent</li>
<li>ユーザ数 42万</li>
<li>100万 PV/day </li>
<li>UU 20,000 人</li>
<li>Traffic &#8211; Outgoing : Max 70 Mbps &#8211; Inbound : Max 25 Mbps</li>
<li>もともとレンタルサーバを組み合わせてやっていた</li>
<li>サーバ増設 + SPOF整理しながら自社インフラに移設 &#8211; 同時に KVM 環境に移行</li>
</ul>

<h3 id="toc_261">旧システムと新システムのアーキテクチャ</h3>

<ul>
<li>HAProxy &#8211; App サーバの local に HAProxy &#8212; 3306 : MySQL master &#8212; 3307 : MySQL slave &#8212; 同様に KyotoTycoon も設定</li>
<li>今も残っている SPOF &#8211; MySQL master &#8212; MHA を試すとか？ &#8211; NFS</li>
</ul>

<h3 id="toc_262">止めずに移行するための準備と仕掛け</h3>

<ul>
<li>段階的に切り替えたかった</li>
<li>手順 &#8211; 新サーバ群立ち上げ &#8212; 合わせてチューニング &#8212;- mk-duplicate-key-checker &#8212; ファイル書き込みの job は新旧それぞれで別々の worker が処理 &#8212; 旧環境にないファイルは Nginx の error_page を使って内部で reverse proxy &#8211; DC 間に VPN &#8212; OpenVPN で構築 &#8212; 100 Mbps 回線で RTT 3-4 ms / スループット 60Mbps &#8211; データ・トラフィックを VPN 経由で移す &#8211; サービス IP を DNS で切り替え &#8212; サービス停止は 1 時間くらいで</li>
</ul>

<h3 id="toc_263">実際の移行作業顛末</h3>

<ul>
<li>4 日に分けて処理して無事終了</li>
<li>ユーザクレームは作業に関係しない箇所のみ &#8211; ユーザにとってのメンテナンスは「不満だった部分が解消される」という期待になる</li>
</ul>

<hr>

<h2 id="toc_264">Mobage オープンプラットフォームの事件簿</h2>

<p>DeNA の zigorou (<a href="http://twitter.com/zigorou">@zigorou</a>) さんの講演。モバゲーオープンプラットフォームの障害事例とその対処法についてのお話でした。大規模サービスの障害事例はとても参考になります。「原因究明」「失敗防止」「知識配布」という項目でまとめているのもわかりやすかったですし、これらの障害報告会を社内で定期的に行なって共有する体制を作っているのはとても良いことだと思いました。</p>

<h3 id="toc_265">DeadLock 多発事件</h3>

<ul>
<li>ある API が突然 DeadLoak が多発するようになった &#8211; もともと Transaction が比較的長い処理だった</li>
<li>原因究明 &#8211; 特定の UPDATE 文が原因 &#8212; 件数カウントのために TRIGGER で summary 作っていた部分 &#8211; 対象データセットに Group という概念があった &#8212; 特定のデータ群をカテゴライズしていた &#8212; 特定の Group に集中してしまうと DEADLOCK になってしまう</li>
<li>失敗防止 &#8211; Trigger ではなく Queue として扱う &#8212; Queue から 100 件とりだして UPDATE 文つくる</li>
<li>知識配布 &#8211; アプリに人気が偏るとデータが集中する &#8212; 設計やモデリングで予見できた障害かもしれない &#8211; Queue のときは Index 不要なのではらない</li>
</ul>

<h3 id="toc_266">INSERT vs DELETE</h3>

<ul>
<li>ある API の古いデータを消そうとしたが DELETE が INSERT に追いつかない</li>
<li>原因処理 &#8211; PURGE 処理 &#8212; master で全力で DELETE すると slave 遅延する &#8212; よくやるのは DB 負荷にかかわらず一律の weight 入れる &#8211; Loop::Sustainable &#8212; 適切な weight をいれてくれる &#8211; SET SQL_LOG_BIN = 0 &#8211; もっと発想を豊かに &#8212; おかわり作戦 &#8212; 余計なデータを PURGE した新しい系統にいれる</li>
<li>失敗防止 &#8211; 極力速く DELETE できる schema を &#8212; DELETE していくのはほぼ無理 &#8212; 構造考えて PARTITIONING をするべき &#8211; ダメなら消し込んでデータ入れ替え</li>
<li>知識配布 &#8211; おかわり作戦 &#8212; DB 運用すると発生する Flagmentation の対策にも鳴る</li>
</ul>

<h3 id="toc_267">有名人問題</h3>

<ul>
<li>有名人ユーザでレスポンス低下したりする</li>
<li>原因究明 &#8211; 取得件数が異常に多い &#8212; TemporaryTable が作られている</li>
<li>失敗防止 &#8211; SQL_CALC_FOUND_ROWS / TemporaryTable は重い &#8212; ユーザを順次取得してやってみる &#8211; Iterator::GroupedRows</li>
</ul>

<h3 id="toc_268">まとめ</h3>

<ul>
<li>失敗から得られることは大きい</li>
<li>スピンアウトで新しいものできる</li>
<li>分業大事</li>
<li>失敗に対して常に問題</li>
</ul>

<hr>

<h2 id="toc_269">Mobageソーシャルゲームにおける大規模サーバ運用 with Perl</h2>

<p>DeNA の riywo (<a href="http://twitter.com/riywo">@riywo</a>) さんの講演。DeNA の内製 SNG の運営におけるチューニングのお話でした。台数が増えると起きてくる問題や、人気が出てイベントなどでアクセスが集中すると起きる問題など、そのアプローチが参考になりました。DevOps 的な問題点についても、規模は小さいながらも同じような状況を見ている立場としてとても共感できるものでした。</p>

<h3 id="toc_270">Application Tuning</h3>

<ul>
<li>アプリケーション台数は多い &#8211; それぞれからつなぐ先を減らすほうが良い</li>
<li>2 つの接続インターフェイスの改善 &#8211; Resolving Module &#8212; DNS での名前解決で失敗するとサービスに影響が出る &#8212; application が MyDNS の中身をまるごとキャッシュ &#8212;- アプリで dns weight みてバランシング &#8212;- DNS 全滅した場合でもローカルキャッシュでしばらく動く &#8211; Handler Socket &#8212; ユーザデータをキャッシュせず直接 DB に取りに行く &#8212; アプリケーション CPU の負荷が下がり高速化した &#8212;- memcached の consistent hash の計算で意外と使ってた</li>
<li>現在のアプリへの &#8220;追加&#8221; は簡単にできる &#8211; インパクトが大きな箇所のところだけ置き換えればいい &#8211; チューニングしたいところだけピンポイントで入れられる</li>
</ul>

<h3 id="toc_271">Database Tuning</h3>

<ul>
<li>一気に成長することで問題が顕在化</li>
<li>DB 分割を繰り返してきた &#8211; 多くの場合は DB 容量の問題が大きく影響 &#8211; database handle を追加して切り替え &#8212; config で同じところを見続けるようにしておく &#8212; メンテナンスで指し先を切り替える</li>
<li>怪盗ロワイヤルのイベント &#8211; 同じお宝を奪い合うにしてみた &#8211; ユーザを探す所が重くなった &#8212; レベルが近い順に探していくため &#8212; レベルのカラム構造を変えて、ざっくりの level-class をつけるようにした &#8211; Lock wait timeout 発生 &#8211; DeadLock 起きにくくする &#8212; ロックを取得する順番を決める &#8211; イベントをすることで既存機能に影響することがある</li>
</ul>

<h3 id="toc_272">DevOps</h3>

<ul>
<li>イベント開始がシェアされてなかった &#8211; シェアされてても全部の問題が予測できるわけではないけど。。。</li>
<li>それぞれの視点で問題を考えてアプローチする &#8211; Dev &#8211; Ops</li>
<li>ちょっとしたプロジェクトマネジメントとして考えている</li>
</ul>

<hr>

<p>LT もレベルが高く面白い発表ばかりだったのですが、聞くことに専念していたのでメモとってませんでした。。。 そして前夜祭のメモまとめてないことに気づいたのであとでまとめます。</p>

<p>2 日目につづく。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[github 上のプロジェクトの fork をプライベートな git サーバで管理]]></title>
    <link href="http://blog.hatak.net/2011/05/31/2165"/>
    <updated>2011-05-31T00:00:00+09:00</updated>
    <id>http://blog.hatak.net/2011/05/31/github-%e4%b8%8a%e3%81%ae%e3%83%97%e3%83%ad%e3%82%b8%e3%82%a7%e3%82%af%e3%83%88%e3%81%ae-fork-%e3%82%92%e3%83%97%e3%83%a9%e3%82%a4%e3%83%99%e3%83%bc%e3%83%88%e3%81%aa-git-%e3%82%b5%e3%83%bc%e3%83%90</id>
    <content type="html"><![CDATA[<p>github で管理されている OSS を利用するとき、少しカスタムして使いたいという場合があったりします。もちろん、fork すれば github 上で自分が push できる状態にはなりますが、カスタムしたバージョンを利用する範囲が社内だったりすると github 以外で管理したくなったりもします。</p>

<p>そこで、こんな感じの構成を目指して、github 上のプロジェクトの fork をプライベートな git サーバで管理してみました。</p>

<p>|プライベートなリモートリポジトリのメインブランチ|origin/master| |github のプロジェクトのメインブランチ|github/upstream|</p>

<!--more-->

<p>事前準備として、プライベート git サーバには push できる空のリポジトリを作っておきます。 (gitosis の場合であれば、gitosis.conf にリポジトリ名を追加しておく感じでいけます)</p>

<p>まず、おおもとのツリーを github から clone して取得します。</p>
<div class="highlight"><pre><code class="text">$ git clone --origin github https://github.com/edavis10/redmine.git
$ cd redmine
$ git config -l
...
remote.github.fetch=+refs/heads/*:refs/remotes/github/*
remote.github.url=https://github.com/edavis10/redmine.git
branch.master.remote=github
branch.master.merge=refs/heads/master
</code></pre>
</div>

<p>ここでは master が github のメインブランチになっています。 今回はオリジナルの master を upstream という名前で扱うようにしたいので、ブランチ名を変更します。</p>
<div class="highlight"><pre><code class="text">$ git branch master
$ git branch -m master upstream
$ git branch upstream
$ git config -l
...
remote.github.fetch=+refs/heads/*:refs/remotes/github/*
remote.github.url=https://github.com/edavis10/redmine.git
branch.upstream.remote=github
branch.upstream.merge=refs/heads/master
</code></pre>
</div>

<p>これでおおもとの master は、ローカルでは github/upstream という名前で扱えるようになりました。 実際にこちらでカスタマイズするのは github/upstream のタグ &#8220;1.2.0&#8243; をベースに使いたいので、ここから master ブランチを切ります。</p>
<div class="highlight"><pre><code class="text">$ git branch master 1.2.0
$ git branch master upstream
</code></pre>
</div>

<p>そして、プライベートな git サーバをリモートリポジトリ &#8220;origin&#8221; として追加します。</p>
<div class="highlight"><pre><code class="text">$ git remote add origin ssh://gitosis@git.example.jp/redmine.git
$ git config branch.master.remote origin
$ git config branch.master.merge refs/heads/master
$ git config -l
...
remote.github.fetch=+refs/heads/*:refs/remotes/github/*
remote.github.url=https://github.com/edavis10/redmine.git
branch.upstream.remote=github
branch.upstream.merge=refs/heads/master
remote.origin.url=ssh://gitosis@git.example.jp/redmine.git
remote.origin.fetch=+refs/heads/*:refs/remotes/origin/*
branch.master.remote=origin
branch.master.merge=refs/heads/master
</code></pre>
</div>

<p>あとはプライベートリポジトリに push すれば完了です。</p>
<div class="highlight"><pre><code class="text">$ git push origin master
$ git push origin upstream
</code></pre>
</div>

<p>これで、origin/master に push/pull し放題になります。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[サイバーエージェント×クックパッド合同勉強会に行ってきた]]></title>
    <link href="http://blog.hatak.net/2011/05/26/1786"/>
    <updated>2011-05-26T00:00:00+09:00</updated>
    <id>http://blog.hatak.net/2011/05/26/%e3%82%b5%e3%82%a4%e3%83%90%e3%83%bc%e3%82%a8%e3%83%bc%e3%82%b8%e3%82%a7%e3%83%b3%e3%83%88%c3%97%e3%82%af%e3%83%83%e3%82%af%e3%83%91%e3%83%83%e3%83%89%e5%90%88%e5%90%8c%e5%8b%89%e5%bc%b7%e4%bc%9a</id>
    <content type="html"><![CDATA[<p>クックパッドさんのオフィスで開催された「<a href="http://techlife.cookpad.com/2011/05/16/amepad/">サイバーエージェント×クックパッド合同勉強会</a>」に参加してきました。 両社で検証や本番導入しているクラウドサービスな話題がメインで、とても興味深いものでした。</p>

<!--more-->

<h2 id="toc_222">OpenStackを検証してみた - オープンソースの仮想化技術 open stack の検証結果の報告</h2>

<p>サイバーエージェントの坂本佳久 (<a href="http://twitter.com/ton_katsu">@ton_katsu</a>) さんの発表。プライベートクラウドを構築するプロジェクトのひとつ、OpenStack を検証した結果のまとめ。</p>

<h3 id="toc_223">OpenStack</h3>

<p>Nova と Swift を組み合わせたプロジェクト。 OpenStack を検証対象として選んだ理由は次のとおり。</p>

<ul>
<li>Eucalypusだとスケールしない (らしい)</li>
<li>ubuntu がサポートする (らしい)</li>
<li>200 人体制で開発が行われている</li>
<li>参加企業として 60 社</li>
<li>KVM, QEmu, Xen など広く対応している</li>
<li>Pythonベースで書かれている</li>
</ul>

<p>AWS と比較すると、下記のような対比でだいたい同じことができる。</p>

<ul>
<li>Amazon EC2

<ul>
<li>Nova</li>
</ul></li>
<li>Amazon S3

<ul>
<li>Glance</li>
<li>OSイメージ登録</li>
<li>Swift</li>
<li>ストレージ</li>
</ul></li>
</ul>

<h3 id="toc_224">システム構成の例</h3>

<p>インスタンスの起動や管理を行う &quot;CloudController&quot; と、この配下に複数の &quot;Computenode&quot; を配置する構成をとる (最小構成では両プロセスを同じマシンに同居させることも可能)。Computenode に hypervisor などをいれ、実際にインスタンスを動作させることとなる。その他、副次的に MySQL や RabbitMQ などのプロセスも利用する。</p>

<h3 id="toc_225">使ってみた</h3>

<p>実際に検証で用いた環境は下記の通り。</p>

<ul>
<li>OpenStack Cactus</li>
<li>Controller

<ul>
<li>ubuntu 10.04</li>
</ul></li>
<li>Computenode

<ul>
<li>ubuntu 10.04 x3</li>
</ul></li>
<li>virtual

<ul>
<li>KVM ベースで CentOS / ubuntu</li>
</ul></li>
</ul>

<p>これらの管理を行うために、 Django ベースの GUI が付属している。WebSocket を利用するため、Safari などで操作する必要がある (Chrome はうまく動作しなかったとのこと)。また、VNC コンソールは Cactus のバージョンでは未実装なので、利用する場合は trunk から取得する必要がある。<br>
その他、API も用意されているので自前で管理ツールを作成することも可能。</p>

<h3 id="toc_226">感想</h3>

<ul>
<li>良かった点

<ul>
<li>ubuntu ではパッケージで提供されているためインストールが簡単</li>
<li>シンプル</li>
<li>Python のためエラーが追いやすい</li>
</ul></li>
<li>苦労した点

<ul>
<li>インスタンスメタデータをどこに取り行けばいいかわからなかった。。</li>
<li>ハイブリッドクラウドがいいかも</li>
</ul></li>
</ul>

<p>来月より検証環境で運用するとのことで、今後のレポートにも注目したいところです。</p>

<h2 id="toc_227">AmebaPico を支える技術 - AWS上に構築された AmebaPico で使用されている技術・開発体制について</h2>

<p>サイバーエージェントの森野耕平 (<a href="http://twitter.com/kohei_april20">@kohei_april20</a>) さんの発表。AmebaPico のアーキテクチャや体制に関して。</p>

<h3 id="toc_228">Ameba Pico</h3>

<p>アメーバピグの海外版として位置づけられているサービス。</p>

<ul>
<li>プラットフォーム

<ul>
<li>facebook</li>
<li>mochimedia</li>
<li>独自 (自前)</li>
</ul></li>
<li>利用ユーザ

<ul>
<li>390万UU、60万MAU</li>
<li>10-20代が中心、男女比 3:7</li>
<li>インドネシア、フィリピン、アメリカが中心</li>
</ul></li>
</ul>

<h3 id="toc_229">アーキテクチャ</h3>

<p>すべて AWS で運用されている。</p>

<ul>
<li>application

<ul>
<li>Tomcat</li>
</ul></li>
<li>socket server

<ul>
<li>ノンブロッキング I/O を使い、軽量データ処理を行う</li>
<li>独自のバイナリプロトコルで細かい大量のコマンドを処理</li>
<li>コマンドとしてのデータをバイナリとしてシリアライズ</li>
<li>イベント駆動でリアルタイム性</li>
</ul></li>
<li>static

<ul>
<li>CDN</li>
<li>Storage</li>
</ul></li>
<li>ZooKeeper

<ul>
<li>システム全体でのロック管理を行う分散ロックシステム</li>
</ul></li>
<li>memcached</li>
<li>MongoDB

<ul>
<li>3台構成のレプリカセットを構築</li>
<li>うち1台は EBS</li>
<li>6シャードで分散</li>
</ul></li>
<li>ElasticMapReduce

<ul>
<li>ログ集計</li>
</ul></li>
<li>pigg と共用の箇所

<ul>
<li>ID管理サーバ</li>
<li>ポイント (サービス内通貨) 管理サーバ</li>
</ul></li>
</ul>

<h3 id="toc_230">AWS の利用</h3>

<ul>
<li>S3

<ul>
<li>static な配信コンテンツを保持</li>
<li>ユーザ行動ログ</li>
</ul></li>
<li>CDN

<ul>
<li>cloudfront を利用</li>
</ul></li>
<li>ElasticMapReduce

<ul>
<li>S3 に保存されたログを解析</li>
</ul></li>
<li>EC2

<ul>
<li>汎用的なサーバインスタンスとして利用</li>
<li>用途に応じて種別を使い分け</li>
<li>small</li>
<li>開発環境</li>
<li>High-CPU</li>
<li>webサーバ</li>
</ul></li>
<li>EBS

<ul>
<li>バックアップなど揮発性があって困る箇所にマウント</li>
</ul></li>
</ul>

<h2 id="toc_231">Flash の利用</h2>

<p>クライアントサイドではまず main.swf のみをロードし、必要に応じてサブモジュールをロードする。</p>

<ul>
<li>shop.swf</li>
<li>room.swf</li>
<li>profile.swf delegate 実装でサーバ接続とモック用を切り分けることで、サーバサイドとクライアントサイド別々の開発が行えるようにしている。</li>
</ul>

<h2 id="toc_232">運用してみて</h2>

<p>EC2 上でサービスを運用してみての総括。</p>

<ul>
<li>良かった点は「手軽さ」

<ul>
<li>DC 借りる必要ないことで海外展開のハードルが下がる</li>
<li>インフラメンバーがいなくても進められた (スモールスタート)</li>
</ul></li>
<li>課題は「重い」こと

<ul>
<li>たまに落ちる</li>
<li>バージニアだからかもしれない？</li>
<li>バージニアで運用中のインスタンスが 60個くらい

<ul>
<li>平均すると 2-3ヶ月に1つ落ちる</li>
<li>最高で4週に4つ落ちたことがある</li>
</ul></li>
<li>メンテナンスの告知が事前に来ることもある</li>
<li>こないこともある</li>
<li>インスタンスが落ちるとどうなるか</li>
<li>応答がなくなる

<ul>
<li>特定ポートだけの場合もある</li>
<li>全体の場合は何も出来ない</li>
</ul></li>
<li>リブートするしかない</li>
<li>落ちなくても、一定時間応答なくなることもある</li>
<li>サービスとして利用する場合</li>
<li>落ちやすいが冗長重視で組めば使える</li>
</ul></li>
</ul>

<p>そして、MongoDB をメインで利用してみての総括。</p>

<ul>
<li>実績

<ul>
<li>処理クエリは 5,000 Read/s (Max)</li>
</ul></li>
<li>問題

<ul>
<li>コネクションプールが枯渇</li>
<li>MongoDB の I/O がボトルネックとなってしまう</li>
<li>シャードを 4→6 に増設することで対処</li>
<li>合わせて I/O パフォーマンスの高いインスタンスを利用するように</li>
<li>オートバランシングの挙動</li>
<li>バランシングに偏りが生じてしまう

<ul>
<li>新規シャード追加時などに特に顕著となる</li>
</ul></li>
<li>現在はオートバランシングを off にして手動で調整</li>
<li>レプリカセットのコンフィグ情報が未反映となるケース</li>
<li>一見正常に動いてるので気付かなかった

<ul>
<li>プライマリ落ちたときにスレーブがうまく動かずに発覚</li>
</ul></li>
<li>コンフィグの反映は全台再起動が必要</li>
</ul></li>
</ul>

<p>MongoDB を大規模に利用しているケースなので、とても興味深いものでした。海外展開の際に DC の場所を気にしなくても良い、というのは AWS ならではのメリットに感じました。</p>

<h2 id="toc_233">毎日の料理を楽しくする画像配信技術</h2>

<p>クックパッドの成田一生 (<a href="http://twitter.com/mirakui">@mirakui</a>) さんの発表。レシピに必須の画像をリアルタイムでリサイズするための Apache モジュール &quot;TOFU&quot; について。</p>

<h3 id="toc_234">従来の画像アップロードの仕組み</h3>

<ul>
<li>アップロードされた画像はアプリケーションサーバがリサイズ

<ul>
<li>サムネイルを NFS に保存</li>
</ul></li>
<li>いくつかの問題点

<ul>
<li>新デザインのプロトタイプで様々な画像サイズを試すことが難しい</li>
<li>デザインに合わせて画像サイズを柔軟に変えたい</li>
<li>試すたびに 800 万枚リサイズ

<ul>
<li>昔はやってた (!)</li>
</ul></li>
<li>デバイス展開の度にデザイン変わるためリサイズが必要

<ul>
<li>サービス出る速度が遅くなる</li>
<li>モチベーションが低下する</li>
</ul></li>
</ul></li>
</ul>

<h3 id="toc_235">そこで新しい方法を模索</h3>

<ul>
<li>現在の規模

<ul>
<li>投稿画像の枚数</li>
<li>800万枚</li>
<li>画像リクエスト</li>
<li>7,000枚/sec</li>
<li>ストレージに NFS を利用</li>
<li>NFS が落ちると全サービスが落ちる</li>
</ul></li>
<li>EC2 への移行を検討中

<ul>
<li>ストレージは S3 にしたい</li>
</ul></li>
</ul>

<h3 id="toc_236">TOFU</h3>

<p>URL に処理内容をマッピングし、リクエストの度に画像をリサイズする Apache モジュール (mod_tofu.so)。</p>
<div class="highlight"><pre><code class="text">/recipes/{:recipe_id}/{:size}/{:hash}
</code></pre>
</div>

<ul>
<li>アタック防止のために末尾に Hash キーを付加</li>
<li>画像処理も可能

<ul>
<li>c</li>
<li>crop (指定したサイズに収める)</li>
<li>q</li>
<li>quality</li>
</ul></li>
<li>細かく指定すれば好きな部分だけ切り取る、もできる</li>
</ul>

<p>画像処理には ImageMagick を利用している。</p>

<ul>
<li>構成

<ul>
<li>C1.XLARGE x6台 で処理</li>
<li>コア数単価が安い</li>
<li>mod_tofu.so は CPU 食うけどメモリ使わない</li>
<li>前段で akamai のキャッシュ</li>
</ul></li>
</ul>

<h2 id="toc_237">苦労話など</h2>

<ul>
<li>ImageMagick と Imlib2

<ul>
<li><a href="http://d.hatena.ne.jp/mirakui/20110123/1295795409">本当は速いImageMagick: サムネイル画像生成を10倍速くする方法</a></li>
</ul></li>
<li>S3

<ul>
<li>s3::ListAllBuckets が正しい結果返さない障害発生</li>
<li>すべての画像が見えなくなった</li>
<li>データは消えないがアクセスできなくなることはある</li>
</ul></li>
<li>akamai or cloudfront

<ul>
<li>cloudfront は元々 S3 のデータを返すものだった</li>
<li>現在は EC2 を origin に使えるようになった</li>
<li>でもやはり akamai は圧倒的に早い</li>
<li>akamai キャッシュヒット率は高くない</li>
<li>90% 程度</li>
<li>試しに ELB 下に Varnish でキャッシュサーバを構築してみたところ 60% ほどヒット

<ul>
<li>TOFU サーバの数を 40% ほど減らせる</li>
</ul></li>
<li>でも Varnish は大容量のメモリが必要なためインスタンスの単価が高い

<ul>
<li>キャッシュサーバ入れるか、TOFU サーバを増やすか、コスト的に微妙なところ</li>
<li>現在はキャッシュサーバは外している</li>
</ul></li>
</ul></li>
</ul>

<p>画像種類もリクエストも多いのにリアルタイムに変換するのは大変そうに思ったのですが、Apache モジュールと聞いて少し納得。キャッシュもうまく組み込んでいて、かなりコストを意識した工夫がされている印象を受けました。</p>

<h2 id="toc_238">AWS移行に向けたクックパッドの取り組み＋α</h2>

<p>クックパッドの菅原元気さんの発表。先日の<a href="http://techlife.cookpad.com/2011/04/22/aws-advantage-seminar/">アマゾンウェブサービスクラウドアドバンテージセミナーで発表された内容</a>をベースに、AWS 移行に向けた全体的なお話。 プレゼン資料がとてもまとまっているので、そちらを直接見たほうが。。。</p>

<h3 id="toc_239">サーバ・ネットワーク構成</h3>

<ul>
<li>現在

<ul>
<li>シンプルな3層構成</li>
<li>別々のセグメントとすることでセキュリティを担保</li>
</ul></li>
<li>新

<ul>
<li>すべてが同じセグメント</li>
<li>セキュリティグループでコントロール</li>
<li>ロール同士の通信は許可</li>
<li>人的ミス対策としてすべてのサーバで iptables 起動</li>
</ul></li>
</ul>

<h3 id="toc_240">AWS でのサーバ</h3>

<ul>
<li>DNS

<ul>
<li>Active-Active 構成で EIP を VIP のように利用</li>
<li>各サーバでは resolv.conf を cron で更新</li>
</ul></li>
<li>AMI

<ul>
<li>基本は CentOS 5.5</li>
<li>各イメージはバージョンをつけて管理</li>
<li>Chef 導入も進めてる</li>
</ul></li>
<li>Nagios + Munin

<ul>
<li>タグをもとに自動で監視項目を設定</li>
<li>起動したインスタンスを cron でチェックして追加</li>
</ul></li>
<li>冗長化

<ul>
<li>ElasticIP を利用</li>
<li>Nagios</li>
<li>LDAP</li>
<li>cron で死活監視</li>
<li>heartbeat への移行</li>
<li>EIP を VIP として利用</li>
<li>マルチキャストが使えないのでユニキャストで</li>
</ul></li>
<li>MySQL

<ul>
<li>EC2 上ではまだ Slave しか稼動していない</li>
</ul></li>
</ul>

<h3 id="toc_241">分散DNSについて</h3>

<p>さすがに全台で resolv.conf を書き換えていくのは大変なのと、いくつかの問題点がクリア出来ない。</p>

<ul>
<li>内容がキャッシュされる</li>
<li>タイムアウト 1s 以下にできない</li>
<li>cron で監視は分単位</li>
</ul>

<p>そのため、分散 DNS を開発。</p>
<div class="highlight"><pre><code class="text">$ ruby gem ddns
</code></pre>
</div>

<p>DNS がそれぞれノードとして機能する動きは、クラウドならではの問題点をクリアするためのひとつの解決策かと思います。現状のサービスを AWS に移行する際の参考になるような、総括的な話でした。</p>

<p>LT もあり、その後の懇親会ではおいしい料理もあり、でとても素敵な勉強会でした。スピーカー＆スタッフの皆様、ありがとうございました！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[git のバックアップ]]></title>
    <link href="http://blog.hatak.net/2011/05/22/1062"/>
    <updated>2011-05-22T00:00:00+09:00</updated>
    <id>http://blog.hatak.net/2011/05/22/git-%e3%81%ae%e3%83%90%e3%83%83%e3%82%af%e3%82%a2%e3%83%83%e3%83%97</id>
    <content type="html"><![CDATA[<p>分散 SCM とはいえ、バックアップはあるとうれしいものです。git のリモートリポジトリが破損した場合などに復元元を探すために、誰が持っているのが最新のリビジョンで、、というような作業が発生することは避けたいからです。</p>

<p>git のリモートリポジトリから別のサーバにバックアップを作成するのは、hooks を利用することで簡単に設定できます。例えば、対象となるリポジトリの post-receive で下記のようなコマンドを設定しておくとできます。</p>

<ul>
<li>バックアップ先のサーバ:ディレクトリは targethost.example.jp:/var/lib/git</li>
<li>バックアップのための SSH 接続で利用するユーザは syncuser</li>
<li>gitosis ユーザは syncuser 権限で git コマンドが利用出来るように visudo を設定</li>
</ul>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c">#!/bin/sh</span>
</span><span class='line'><span class="c">#####</span>
</span><span class='line'><span class="c"># hooks/post-receive</span>
</span><span class='line'><span class="c">#####</span>
</span><span class='line'>
</span><span class='line'><span class="nv">MIRROR_HOST</span><span class="o">=</span><span class="s1">&#39;targethost.example.jp&#39;</span>
</span><span class='line'><span class="nv">REPO_NAME</span><span class="o">=</span><span class="sb">`</span><span class="nb">pwd</span> | perl -e <span class="s1">&#39;$t=&lt;stdin&gt;;$t=~ s!^.*/!!;print $t&#39;</span><span class="sb">`</span>
</span><span class='line'>sudo -u syncuser -H git push :mirror syncuser@<span class="k">${</span><span class="nv">MIRROR_HOST</span><span class="k">}</span>:/var/lib/git/<span class="k">${</span><span class="nv">REPO_NAME</span><span class="k">}</span>
</span></code></pre></td></tr></table></div></figure>

<p>&quot;:mirror&quot; オプションを付けることで、バックアップ先にも bare のままディレクトリが作成されます。 リモートリポジトリとして利用するサーバと別のサーバで Redmine や Trac、あるいは gitweb などを動作させてリポジトリブラウザを利用する場合などでも bare を付けます。</p>

<p>hooks/post-receive は、リポジトリに加わる変更を受信したタイミングで実行される hook script です。cron などで仕込むものとは異なり、push されたタイミングで sync されるので無駄にコネクションが張られることがありません。 ただし、push するタイミングで別サーバへの push が実行されるため、ユーザからみると push 自体の時間が少し長くなるのが欠点です。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[gitosis で作るプライベートな git サーバ]]></title>
    <link href="http://blog.hatak.net/2011/05/18/571"/>
    <updated>2011-05-18T00:00:00+09:00</updated>
    <id>http://blog.hatak.net/2011/05/18/gitosis-%e3%81%a7%e4%bd%9c%e3%82%8b%e3%83%97%e3%83%a9%e3%82%a4%e3%83%99%e3%83%bc%e3%83%88%e3%81%aa-git-%e3%82%b5%e3%83%bc%e3%83%90</id>
    <content type="html"><![CDATA[<p>業務で使い始めた Git ですが、高機能過ぎて未だに使いこなせている自信がありません。 一方で、かつて利用していた Subversion はコマンドを忘れてしまって使うたびにググるほどに記憶が抜けつつあります。</p>

<p>そんな Git を複数メンバー・複数環境で利用する場合、マスターリポジトリを利用することがあります。これにより、Subversion のような中央集約型のソースコード管理をしつつも Git の恩恵を受ける開発スタイルを取ることができるます。 マスターリポジトリとして <a href="http://github.com/">GitHub</a> を利用するのが最も手っ取り早いですが、プライベート（= メンバーのみが閲覧できる）なリポジトリを作成するためには有料オプションにしなければなりません。しかも地味に高い。</p>

<p>こんな時、gitosis を利用すると手軽にプライベートな Git サーバを構築することができます。もちろん、リポジトリを利用するメンバー全員が SSH での接続ができるサーバに bare リポジトリを作ることでも Git サーバとして機能しますが、それでも gitosis を使う優位性は以下のような点にあります。</p>

<ul>
<li>公開鍵認証を用い、通信にSSHを利用するため安全に利用できる</li>
<li>公開鍵でユーザを識別し、リポジトリに対するアクセス制御が設定できる</li>
<li>サーバにアカウントとは切り離して、リポジトリへのアクセスアカウントの作成ができる</li>
</ul>

<p>gitosis はマスターリポジトリとして利用するサーバのみインストールします。リモートから clone / pull / push をするクライアントには、通常通りの Git がインストールされていれば利用することができます。</p>

<!--more-->

<h2 id="toc_214">パッケージ導入</h2>

<p>gitosis は python で記述され、gitで管理されているプロジェクトです。 CentOS の場合、EPEL リポジトリに Git / gitosis 共にパッケージが存在するので、これを利用することで簡単にインストールできます。</p>
<div class="highlight"><pre><code class="text">$ sudo yum install git python-setuptools gitosis
</code></pre>
</div>

<p>この方法で導入した場合、gitosis ユーザが合わせて作成されます。</p>

<ul>
<li>uid: gitosis</li>
<li>home dir: /var/lib/gitosis</li>
</ul>

<h2 id="toc_215">初期設定</h2>

<p>gitosis の設定は、 gitosis 管理リポジトリのファイルを変更し push することで反映されます。 設定を行うためには、管理ユーザとして最低一人の公開鍵をセットしなければなりません。ここでは、Git サーバ上の現在の操作ユーザの鍵を管理ユーザとしてセットする例を示します。</p>
<div class="highlight"><pre><code class="text">$ cd /var/lib/gitosis
$ sudo -H -u gitosis gitosis-init &lt; ~/.ssh/id_rsa.pub
</code></pre>
</div>

<p>これで、gitosis のホームに &quot;gitosis&quot; ,&quot;repositories&quot; という2つのディレクトリが生成されます。<br>
この gitosis 管理リポジトリを、登録した鍵を持つクライアント（ここでは同一ホスト）からcloneし、設定します。</p>
<div class="highlight"><pre><code class="text">$ cd ~/work
$ git clone gitosis@localhost:gitosis-admin.git
</code></pre>
</div>

<p>設定を変更後、push することで Hooks のスクリプトが実行されることで key が gitosis ユーザの authorized_keys に追記されていきます。 この authorized_keys には command が併記されているため、git のリモートリポジトリを操作する以外のコマンドが実行できないようになっているのです。</p>

<h3 id="toc_216">新規ユーザの追加</h3>

<p>新規ユーザの追加は、*.pub ファイルを作成して該当するグループに追記、push するだけです。 gitosis では、グループ毎に権限をコントロールする形式を取ります。このため、ユーザが複数のグループに所属しているとうまく動作しないことがあります。 *.pub は単なる authorized_keys なので、1行にひとつの公開鍵を書く形式になっていれば複数設定可能です。</p>

<h3 id="toc_217">新規リポジトリの追加</h3>

<p>新規リポジトリの追加は、gitosis.conf に変更を加えて push するだけです。空のまま pull すると init されるだけですが、追加して push すれば大丈夫です。</p>

<h2 id="toc_218">設定のコツ</h2>

<p>keydir 以下に公開鍵ごとにファイルを作成し、 gitosis.conf に公開鍵のファイル名 (.pub を除く) を設定していきます。</p>
<div class="highlight"><pre><code class="text">[gitosis]

[group gitosis-admin]
writable = gitosis-admin
members = admin

[group development]
writable = misc/sandbox project test
members = hatak hoge fuga
</code></pre>
</div>

<h3 id="toc_219">サブディレクトリ</h3>

<p>リポジトリはサブディレクトリに入れることができます。 上記 sandbox の場合は次のようになります。</p>

<ul>
<li>Clone 用 URL : ssh://gitosis@localhost/misc/sandbox.git</li>
<li>サーバ内ファイルシステム: /var/lib/gitosis/repositories/misc/sandbox.git</li>
</ul>

<p>サブディレクトリは予め作成しておく必要がありますが、こうすることで乱立するリポジトリを階層分けして整理することができます。</p>
<div class="highlight"><pre><code class="text">$ sudo -H -u gitosis mkdir /var/lib/gitosis/repositories/misc
</code></pre>
</div>

<h3 id="toc_220">config の改行</h3>

<p>gitosis.conf ではユーザが多いときなどバックスラッシュを入れることで、設定ファイル内でも改行することができます。 ユーザが多いときなどに可読性を上げることができ、とても便利です。</p>

<h2 id="toc_221">関連するページ</h2>

<ul>
<li><a href="http://scie.nti.st/2007/11/14/hosting-git-repositories-the-easy-and-secure-way">Hosting Git repositories, The Easy (and Secure) Way</a></li>
<li><a href="http://labs.gree.jp/blog/2011/03/2885/">多人数開発で Git を使う場合の環境構築 | GREE Engineers&#39; Blog</a></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MacOSX のローカルの DNS キャッシュ]]></title>
    <link href="http://blog.hatak.net/2011/05/17/335"/>
    <updated>2011-05-17T00:00:00+09:00</updated>
    <id>http://blog.hatak.net/2011/05/17/macosx-%e3%81%ae%e3%83%ad%e3%83%bc%e3%82%ab%e3%83%ab%e3%81%ae-dns-%e3%82%ad%e3%83%a3%e3%83%83%e3%82%b7%e3%83%a5</id>
    <content type="html"><![CDATA[<p>DNS の設定を触るとき、ローカルのキャッシュが変わっていないためにハマることが多々あります。Mac の場合、ターミナルで dig して変更を確認してもブラウザで開けなかったりするわけで。</p>

<p>これは、MacOSX 内部で DNS 解決の結果をキャッシュする機能が働いているためです。 キャッシュをコントロールするためには dscacheutil コマンドを使います。</p>

<figure class='code'><figcaption><span>dscacheutil</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">Usage: dscacheutil -h</span>
</span><span class='line'><span class="go">       dscacheutil -q category [-a key value]</span>
</span><span class='line'><span class="go">       dscacheutil -cachedump [-buckets] [-entries [category]]</span>
</span><span class='line'><span class="go">       dscacheutil -configuration</span>
</span><span class='line'><span class="go">       dscacheutil -flushcache</span>
</span><span class='line'><span class="go">       dscacheutil -statistics</span>
</span></code></pre></td></tr></table></div></figure>

<p>キャッシュをクリアするのは &quot;-flushcache&quot; オプションをつけます。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="gp">$</span> dscacheutil -flushcache
</span></code></pre></td></tr></table></div></figure>

<p>sudo しなくてもユーザ権限でできるので安心。</p>

<!--more-->

<p>実際にキャッシュされてるデータを調べるにはこんな感じ。</p>

<figure class='code'><figcaption><span>dscacheutil -q host -a name blog.hatak.net</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">name: vps02.sakura.dwmp.jp</span>
</span><span class='line'><span class="go">alias: blog.hatak.net</span>
</span><span class='line'><span class="go">ip_address: 49.212.41.49</span>
</span></code></pre></td></tr></table></div></figure>

<figure class='code'><figcaption><span>dig blog.hatak.net</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">;; ANSWER SECTION:</span>
</span><span class='line'><span class="go">blog.hatak.net.     600 IN  CNAME   vps02.sakura.dwmp.jp.</span>
</span><span class='line'><span class="go">vps02.sakura.dwmp.jp.   600 IN  A   49.212.41.49</span>
</span></code></pre></td></tr></table></div></figure>

<p>ちゃんと dig の結果と同じものがキャッシュされてました。CNAME の場合は alias として表示されるようですね。 IP からの逆引きも調べてみました。</p>

<figure class='code'><figcaption><span>dscacheutil -q host -a ip_address 49.212.41.49</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">name: www30255u.sakura.ne.jp</span>
</span><span class='line'><span class="go">alias: 49.41.212.49.in-addr.arpa</span>
</span><span class='line'><span class="go">ip_address: 49.212.41.49</span>
</span></code></pre></td></tr></table></div></figure>

<figure class='code'><figcaption><span>dig -x 49.212.41.49</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">;; ANSWER SECTION:</span>
</span><span class='line'><span class="go">49.41.212.49.in-addr.arpa. 3600 IN  PTR www30255u.sakura.ne.jp.</span>
</span></code></pre></td></tr></table></div></figure>

<p>逆引きの委譲をしていないので管理用のドメインが返ってきてしまいますが、これも dig の結果と同じものになってます。 &#8220;ds&#8221; というコマンド名のとおり、もともと DirectoryService のキャッシュを操作するためのもののようで、DNS に限ったコマンドではなさそうです。</p>

<figure class='code'><figcaption><span>dscacheutil -q user -a name hatak</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">name: hatak</span>
</span><span class='line'><span class="go">password: ********</span>
</span><span class='line'><span class="go">uid: 501</span>
</span><span class='line'><span class="go">gid: 20</span>
</span><span class='line'><span class="go">dir: /Users/hatak</span>
</span><span class='line'><span class="go">shell: /bin/bash</span>
</span><span class='line'><span class="go">gecos: hatak</span>
</span></code></pre></td></tr></table></div></figure>
]]></content>
  </entry>
  
</feed>
